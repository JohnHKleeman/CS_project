{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mckak\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy: 0.19.1\n",
      "numpy: 1.13.3\n",
      "pandas: 0.22.0\n",
      "matplotlib: 2.1.0\n",
      "sklearn: 0.19.1\n"
     ]
    }
   ],
   "source": [
    "import sys, pdb, warnings, scipy, matplotlib, sklearn\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cPickle as pkl\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, Ridge\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import cross_validation #might be model_selection <--- this is the new one\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import preprocessing \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style(\"whitegrid\")\n",
    "sys.setrecursionlimit(15000)\n",
    "%matplotlib inline\n",
    "\n",
    "print('scipy: {}'.format(scipy.__version__))\n",
    "print('numpy: {}'.format(np.__version__))\n",
    "print('pandas: {}'.format(pd.__version__))\n",
    "print('matplotlib: {}'.format(matplotlib.__version__)) \n",
    "print('sklearn: {}'.format(sklearn.__version__))\n",
    "\n",
    "#our modules see: CS_Project/cspython directory\n",
    "from cspython.scraper import modifiedSoup\n",
    "from cspython.data_processing import process_scrapped\n",
    "import cspython.analysis as a\n",
    "\n",
    "#import xlrd\n",
    "#import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose of this notebook: Create a dataset of aggregate team statistics with a resolution of 1 row per team per match\n",
    "\n",
    "   ## There are 4 sections:\n",
    "       1 Data Processing functions, which complete the processing step of the raw scraped data\n",
    "       2 Data Agggregation functions, which aggregate the data to the team level for each match\n",
    "       3 Data set creation: calls the functions from the previous sections to create the data\n",
    "           note: the data are temporaly related, the statistics in every row are based on the \n",
    "           current match, and all previous matches (for which we have data)\n",
    "       4 Create X y functions, which will be used to create test train sets for cross validation\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Data Processing functions\n",
    "\n",
    "    creates a giant dataframe containing all of the information scraped by the scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_dfs(big_data, overview):\n",
    "    first=True\n",
    "    cols = ['map','round_num','half','match_id','series_id','ending','CT','T','side_winner','winner','team_A','team_B','team_A_score','team_B_score','match_num','team_players','K-D','+/-','ADR','KAST','Rating2.0','nicknames']\n",
    "    dfs = []\n",
    "    for idx, series_data in big_data.iteritems():\n",
    "        series_data_m = merge_matches(series_data)\n",
    "        series_data_m[\"date\"] = overview.loc[overview.id == idx, 'date']\n",
    "        series_data_mo = merge_overview(series_data_m, series_data)\n",
    "        series_data_mos = merge_scoreboards(series_data_mo, series_data)\n",
    "        series_data_mosm = match_data_board_changer(series_data_mos, series_data)\n",
    "        dfs.append(series_data_mosm)    \n",
    "        new_cols = list(set(series_data_mosm.columns) -set(cols))\n",
    "        cols += new_cols\n",
    "    data = pd.concat(dfs)\n",
    "    data = data.loc[:,cols]\n",
    "    data = data.reset_index()\n",
    "    return data\n",
    "\n",
    "def merge_matches(series_data):\n",
    "    for d in range(0,len(series_data['matches'])):\n",
    "        if d == 0:\n",
    "            series_data['matches'][d] = series_data['matches'][d].rename(index = str, columns={ series_data['matches'][d].columns[10] : \"team_A\", series_data['matches'][d].columns[11] : \"team_B\" })\n",
    "            series_data_m = series_data['matches'][d]\n",
    "        else:\n",
    "            series_data['matches'][d] = series_data['matches'][d].rename(index = str, columns={ series_data['matches'][d].columns[10] : \"team_A\", series_data['matches'][d].columns[11] : \"team_B\" })\n",
    "            series_data_m = pd.concat([series_data_m, series_data['matches'][d]])\n",
    "    \n",
    "    return series_data_m\n",
    "    #should work for concact the matches together\n",
    "    \n",
    "def merge_overview(series_data_m, series_data):\n",
    "    series_data['match_overview']['team_A_name'] = series_data['match_overview'].columns[4]\n",
    "    series_data['match_overview']['team_B_name'] = series_data['match_overview'].columns[5]\n",
    "    \n",
    "    series_data['match_overview'].loc[(series_data['match_overview']['winner'] == series_data['match_overview'].columns[4]),'loser_of_match'] = series_data['match_overview'].team_B_name\n",
    "    series_data['match_overview'].loc[(series_data['match_overview']['winner'] != series_data['match_overview'].columns[4]),'loser_of_match'] = series_data['match_overview'].team_A_name\n",
    "    series_data['match_overview'] = series_data['match_overview'].rename(index = str, columns ={series_data['match_overview'].columns[3]: \"winner_of_match\",series_data['match_overview'].columns[4]: \"team_A_score\",series_data['match_overview'].columns[5]: \"team_B_score\"})\n",
    "    \n",
    "    \n",
    "    series_data_mo = pd.merge(series_data_m, series_data['match_overview'], on=['match_id', 'map', 'series_id'])\n",
    "    \n",
    "    return series_data_mo\n",
    "#works at merging matches with match_overviewb\n",
    "\n",
    "def merge_scoreboards(series_data_mo, series_data):    \n",
    "   \n",
    "    for i in range(len(series_data['scoreboards'][0])):\n",
    "        series_data['scoreboards'][0][i]['match_num'] = i+1\n",
    "        #pdb.set_trace()\n",
    "        series_data['scoreboards'][0][i]['player_team_name'] = series_data_mo.loc[(series_data_mo['match_num']== i+1),'team_A_name'].unique()[0]\n",
    "        series_data['scoreboards'][0][i] = series_data['scoreboards'][0][i].rename(index = str, columns={ series_data['scoreboards'][0][i].columns[0] : \"team_players\" })\n",
    "        \n",
    "        series_data['scoreboards'][1][i]['match_num'] = i+1\n",
    "        series_data['scoreboards'][1][i]['player_team_name'] = series_data_mo.loc[(series_data_mo['match_num']== i+1),'team_B_name'].unique()[0]\n",
    "        series_data['scoreboards'][1][i] = series_data['scoreboards'][1][i].rename(index = str, columns={ series_data['scoreboards'][1][i].columns[0] : \"team_players\"})\n",
    "        \n",
    "        new_df = pd.concat([series_data['scoreboards'][0][i], series_data['scoreboards'][1][i]])\n",
    "        \n",
    "        if i == 0:\n",
    "            con_df = new_df\n",
    "        else:\n",
    "            con_df = pd.concat([con_df, new_df])\n",
    "   \n",
    "    series_data_mos = pd.merge(series_data_mo, con_df, how='outer', on='match_num')\n",
    "    series_data_mos['nicknames'] = series_data_mos['team_players'].str.split(expand = True)[3]\n",
    "    return series_data_mos\n",
    "\n",
    "       \n",
    "def match_data_board_changer(series_data_mos,series_data):\n",
    "    board_name = ['first_kills','who_kill_who', 'awp_kills']\n",
    "    for idx, a in enumerate(series_data['match_data']):\n",
    "        new_df = pd.DataFrame()\n",
    "        for idx1, c in enumerate(board_name):    \n",
    "            new_board_c = pd.DataFrame()\n",
    "            new_board_r= pd.DataFrame()\n",
    "            names_c = a[c].set_index('Unnamed: 0').columns\n",
    "            for b in names_c:\n",
    "                new_board_c[b+'_'+c] = a[c].set_index('Unnamed: 0')[b].str.split(pat = ':', expand = True)[0]\n",
    "               \n",
    "            names_r = a[c].set_index('Unnamed: 0').T.columns\n",
    "            for b in names_r:\n",
    "                new_board_r[b+'_'+c] = a[c].set_index('Unnamed: 0').T[b].str.split(pat = ':', expand = True)[1]\n",
    "            new_board_c['nicknames'] = new_board_c.index\n",
    "            new_board_r['nicknames'] = new_board_r.index\n",
    "            \n",
    "            board_df = new_board_c.append(new_board_r)\n",
    "            \n",
    "            if idx1 == 0:\n",
    "                new_df = board_df\n",
    "            else:\n",
    "                new_df = pd.merge(new_df, board_df, on = 'nicknames')\n",
    "        if idx == 0:\n",
    "            new_df['match_num'] = 1+idx\n",
    "            con_df = new_df\n",
    "        else:\n",
    "            new_df['match_num'] = 1+idx\n",
    "            try:\n",
    "                con_df = con_df.append(new_df, ignore_index=True)\n",
    "            except:\n",
    "                print con_df.columns\n",
    "                print new_df.columns\n",
    "    con_df = con_df.loc[:, ~con_df.columns.duplicated()]\n",
    "    series_data_mosm = pd.merge(series_data_mos, con_df, on=['nicknames','match_num'])\n",
    "    return series_data_mosm\n",
    "\n",
    "\n",
    "#works at adding match_num to scoreboards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Aggregation functions\n",
    "    takes the data created by above functions, where each row is 1 player in 1 match, and aggregates \n",
    "    the player data so each row is 1 team in match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_fwa_dr_columns(data, col_list):  # first k , awp, who, divided by rounds \n",
    "    columns = pd.Series(data.columns)\n",
    "    for a in col_list:\n",
    "        col = columns[columns.str.contains(a)]\n",
    "        data[a+'_sum_dr'] = data[col].convert_objects(convert_numeric = True).sum(axis = 1) / (data['team_A_score'] + data['team_B_score'])\n",
    "    r = data.loc[:, data.columns != 'date'].apply(pd.to_numeric, errors='ignore')\n",
    "    r['date'] = data.date\n",
    "    return r\n",
    "        \n",
    "def create_fwadr_his(data, col_list):   # column with historic awp, first ,who_killwho of player vs player. \n",
    "    match_id = data.match_id.unique()\n",
    "    players = data.nicknames.unique()\n",
    "    for a in col_list:\n",
    "        grouping = data.groupby(['nicknames', 'match_id'])[a+'_sum_dr'].mean() \n",
    "        grouping = pd.DataFrame(grouping)\n",
    "        grouping = grouping.reset_index()\n",
    "        grouping = grouping.groupby(['nicknames'])[a+'_sum_dr'].sum()/ grouping.groupby(['nicknames'])[a+'_sum_dr'].count()\n",
    "        grouping = pd.DataFrame(grouping)\n",
    "        grouping = grouping.reset_index()\n",
    "        grouping = grouping.rename(index=str, columns={a +'_sum_dr': a + '_sum_dr_hist'})\n",
    "        data = pd.merge(data, grouping, on = 'nicknames')\n",
    "        \n",
    "    return data\n",
    "\n",
    "def create_matches_count(data): # how many matches a person has played\n",
    "    grouping = data.groupby(['nicknames', 'match_id'])['ADR'].count()\n",
    "    grouping = pd.DataFrame(grouping)\n",
    "    grouping = grouping.reset_index()\n",
    "    grouping = grouping.groupby(['nicknames'])['ADR'].count()\n",
    "    grouping = pd.DataFrame(grouping)\n",
    "    grouping = grouping.reset_index()\n",
    "    grouping = grouping.rename(index=str, columns={'ADR': 'matches_played_player'})\n",
    "    data = pd.merge(data, grouping, on = 'nicknames')\n",
    "    return data\n",
    "    \n",
    "def create_avdamage_his(data):  # column with historic average damage of individual \n",
    "    grouping = data.groupby(['nicknames', 'match_id'])['ADR'].mean() \n",
    "    grouping = pd.DataFrame(grouping)\n",
    "    grouping = grouping.reset_index()\n",
    "    grouping = grouping.groupby(['nicknames'])['ADR'].sum()/ grouping.groupby(['nicknames'])['ADR'].count()\n",
    "    grouping = pd.DataFrame(grouping)\n",
    "    grouping = grouping.reset_index()\n",
    "    grouping = grouping.rename(index=str, columns={'ADR': 'ADR_hist'})\n",
    "    data = pd.merge(data, grouping, on = 'nicknames')\n",
    "    \n",
    "    return data\n",
    "\n",
    "def create_map_win_loss_his(data):  # team total win and loses on map with total times played on map\n",
    "    maps = data.map.unique()\n",
    "    teams = data.player_team_name.unique()\n",
    "    match_id = data.match_id.unique()\n",
    "    for a in maps:\n",
    "        data[a + \"_win_his\"] = 0\n",
    "        data[a + \"_loss_his\"] = 0\n",
    "        data[a + \"_total_played\"] = 0\n",
    "    for a in match_id:\n",
    "        map_for_match = data.loc[(data['match_id'] == a) ,'map'].unique()\n",
    "        winner_of_map = data.loc[(data['match_id'] == a), 'winner_of_match'].unique()\n",
    "        loser_of_map = data.loc[(data['match_id'] == a), 'loser_of_match'].unique()\n",
    "        data.loc[(data['player_team_name'] == winner_of_map[0]), [map_for_match[0] + \"_win_his\", map_for_match[0] +'_total_played']] += 1\n",
    "        data.loc[(data['player_team_name'] == loser_of_map[0]), [map_for_match[0] + \"_loss_his\", map_for_match[0] +'_total_played']] += 1 \n",
    "       \n",
    "    return data\n",
    "\n",
    "\n",
    "def create_map_win_his_per(data): #percentage team total win and loses on map\n",
    "    teams = data.player_team_name.unique()\n",
    "    maps = data.map.unique()\n",
    "    for a in maps:\n",
    "        data[a + '_win_perc_map'] = 0\n",
    "        for b in teams:\n",
    "            pg = (data.player_team_name == b) \n",
    "            data.loc[pg,a + '_win_perc_map'] = data.loc[pg, a + \"_win_his\"].unique()[0] / float((data.loc[pg, a + \"_win_his\"].unique()[0] + data.loc[pg, a + \"_loss_his\"].unique()[0])) \n",
    "    data = data.fillna(0)        \n",
    "    return data    \n",
    "\n",
    "def create_rounds_won_vs_team_his(data): # team rounds won vs another team\n",
    "    grouping = data.groupby(['match_id','map','team_A_name','team_B_name', 'team_A_score', 'team_B_score'])['round_num'].count()\n",
    "    grouping = pd.DataFrame(grouping)\n",
    "    grouping = grouping.add_suffix('_Count').reset_index()\n",
    "    grouping = grouping.groupby(['team_A_name', 'team_B_name']).sum()\n",
    "    grouping = pd.DataFrame(grouping)\n",
    "    grouping = grouping.add_suffix('_Count').reset_index()\n",
    "    forward = grouping.team_A_name+grouping.team_B_name\n",
    "    reverse = grouping.team_B_name+grouping.team_A_name\n",
    "    for idx, val in enumerate(forward):\n",
    "        for idx2, val2 in enumerate(reverse):\n",
    "            if val == val2 and idx < idx2:\n",
    "                grouping.loc[idx,'team_A_score_Count'] += grouping.loc[idx2,'team_B_score_Count']\n",
    "                grouping.loc[idx,'team_B_score_Count'] += grouping.loc[idx2,'team_A_score_Count']\n",
    "                grouping.loc[idx2,'team_B_score_Count'] = grouping.loc[idx,'team_A_score_Count']\n",
    "                grouping.loc[idx2,'team_A_score_Count'] = grouping.loc[idx,'team_B_score_Count']\n",
    "            elif val == val2 and idx > idx2:\n",
    "                grouping.loc[idx2,'team_B_score_Count'] = grouping.loc[idx,'team_A_score_Count']\n",
    "                grouping.loc[idx2,'team_A_score_Count'] = grouping.loc[idx,'team_B_score_Count']\n",
    "    \n",
    "    grouping = grouping.drop('round_num_Count_Count', axis = 1)\n",
    "    col1 = list(grouping.team_A_name.unique())\n",
    "    col2  = list(grouping.team_B_name.unique())\n",
    "    col = col1 + col2\n",
    "    col = list(set(col))\n",
    "    data = pd.merge(data,grouping, on=['team_A_name', 'team_B_name']) \n",
    "    for a in col:\n",
    "        data['rd_total_his_'+ a] = 0\n",
    "        data.loc[(data.player_team_name != a) & (data.team_A_name == a) , 'rd_total_his_'+ a]=data.team_B_score_Count\n",
    "        data.loc[(data.player_team_name != a) & (data.team_B_name == a) , 'rd_total_his_'+ a]=data.team_A_score_Count\n",
    "        bgrouping = data.groupby(['player_team_name'])['rd_total_his_'+ a].max()\n",
    "        bgrouping = pd.DataFrame(bgrouping)\n",
    "        bgrouping = bgrouping.reset_index()\n",
    "        data = data.drop('rd_total_his_'+ a, axis = 1)\n",
    "        data = pd.merge(data, bgrouping, on = 'player_team_name')\n",
    "       \n",
    "    return data  \n",
    "\n",
    "def create_total_team_rd_map_his(data):\n",
    "    grouping = data.groupby(['map','team_A_name', 'team_A_score'])['round_num'].count()\n",
    "    grouping = pd.DataFrame(grouping)\n",
    "    grouping = grouping.add_suffix('_Count').reset_index()\n",
    "    grouping = grouping.groupby(['map','team_A_name'])[ 'team_A_score'].sum()\n",
    "    grouping = pd.DataFrame(grouping)\n",
    "    grouping = grouping.add_suffix('_Count').reset_index()\n",
    "    fgrouping = data.groupby(['player_team_name','map','team_B_name', 'team_B_score'])['round_num'].count()\n",
    "    fgrouping = pd.DataFrame(fgrouping)\n",
    "    fgrouping = fgrouping.add_suffix('_Count').reset_index()\n",
    "    fgrouping = fgrouping.groupby(['map','team_B_name'])[ 'team_B_score'].sum()\n",
    "    fgrouping = pd.DataFrame(fgrouping)\n",
    "    fgrouping = fgrouping.add_suffix('_Count').reset_index()\n",
    "    fgrouping = fgrouping.rename(index=str, columns={\"team_B_name\": \"team_A_name\", 'team_B_score_Count': 'team_A_score_Count'})\n",
    "    merged = pd.concat([grouping, fgrouping], axis = 0)\n",
    "    merged.groupby(['map', 'team_A_name'])['team_A_score_Count'].sum()\n",
    "    merged = pd.DataFrame(merged)\n",
    "    merged = merged.reset_index(drop = True)\n",
    "    merged = merged.rename(index=str, columns={\"team_A_name\": \"player_team_name\", \"team_A_score_Count\": 'total_team_rd_map'})\n",
    "    merged = merged.groupby(['player_team_name', 'map']).sum()\n",
    "    merged = pd.DataFrame(merged)\n",
    "    merged = merged.reset_index()\n",
    "    for a in list(merged.map.unique()):\n",
    "        merged.loc[:,'total_team_rd_'+ a] = 0\n",
    "        merged.loc[(merged.loc[:, 'map'] == a), 'total_team_rd_'+ a] = merged.loc[:,'total_team_rd_map']\n",
    "        ok_map = merged.groupby(['player_team_name'])['total_team_rd_'+ a].max()\n",
    "        ok_map = pd.DataFrame(ok_map)\n",
    "        ok_map = ok_map.reset_index()\n",
    "        data = pd.merge(data, ok_map, on = 'player_team_name')\n",
    "    return data\n",
    "    \n",
    "def create_faw_map_his(data, col_list):\n",
    "    for a in col_list:\n",
    "        fk_map = data.groupby(['match_id','nicknames', 'map'])[a+'_sum_dr'].mean()\n",
    "        fk_map = pd.DataFrame(fk_map)\n",
    "        fk_map = fk_map.reset_index()\n",
    "        fk_map = fk_map.groupby(['nicknames', 'map'])[a+'_sum_dr'].mean()\n",
    "        fk_map = pd.DataFrame(fk_map)\n",
    "        fk_map = fk_map.reset_index()\n",
    "        for b in list(fk_map.map.unique()):\n",
    "            fk_map.loc[:,a+'_'+b +'_dr_hist'] = 0 \n",
    "            fk_map.loc[(fk_map.loc[:, 'map'] == b), a+'_'+b+'_dr_hist'] = fk_map.loc[:,a + '_sum_dr']\n",
    "            ok_map = fk_map.groupby(['nicknames'])[a+'_'+b+'_dr_hist'].max()\n",
    "            ok_map = pd.DataFrame(ok_map)\n",
    "            ok_map = ok_map.reset_index()\n",
    "            data = pd.merge(data, ok_map, on = 'nicknames')\n",
    "    return data\n",
    "\n",
    "def create_avdamage_map_his(data):# historic average damage of individual for each map\n",
    "    map_adr = data.groupby(['match_id','nicknames', 'map'])['ADR'].mean()\n",
    "    map_adr = pd.DataFrame(map_adr)\n",
    "    map_adr = map_adr.reset_index()\n",
    "    map_adr = map_adr.groupby(['nicknames', 'map'])['ADR'].mean()\n",
    "    map_adr = pd.DataFrame(map_adr)\n",
    "    map_adr = map_adr.reset_index()\n",
    "    for a in list(map_adr.map.unique()):\n",
    "        map_adr.loc[:,'ADR_his_'+ a] = 0\n",
    "        map_adr.loc[(map_adr.loc[:, 'map'] == a), 'ADR_his_'+ a] = map_adr.loc[:,'ADR']\n",
    "        ok_map = map_adr.groupby(['nicknames'])['ADR_his_'+ a].max()\n",
    "        ok_map = pd.DataFrame(ok_map)\n",
    "        ok_map = ok_map.reset_index()\n",
    "        data = pd.merge(data, ok_map, on = 'nicknames')\n",
    "    return data\n",
    "\n",
    "def create_opponent_team_col(data):\n",
    "    data.loc[:,'player_team_opponent'] = np.nan\n",
    "    data.loc[(data['team_A_name'] != data['player_team_name']),'player_team_opponent'] = data.loc[:,'team_A_name']\n",
    "    data.loc[(data['team_B_name'] != data['player_team_name']),'player_team_opponent'] = data.loc[:,'team_B_name']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_slice(data, col_list):\n",
    "    data = create_fwa_dr_columns(data, col_list)\n",
    "    data = create_fwadr_his(data,col_list)\n",
    "    data = create_avdamage_his(data)\n",
    "    data = create_map_win_loss_his(data)\n",
    "    data = create_map_win_his_per(data)\n",
    "    data = create_rounds_won_vs_team_his(data)\n",
    "    data = create_total_team_rd_map_his(data)\n",
    "    data = create_avdamage_map_his(data)\n",
    "    data = create_faw_map_his(data, col_list)\n",
    "    data = create_matches_count(data)\n",
    "    data = create_opponent_team_col(data)\n",
    "    \n",
    "    data_adv = data.loc[:, 'first_kills_sum_dr_hist':'player_team_opponent']\n",
    "    data_adv['match_id'] = data['match_id']\n",
    "    data_adv['player_team_name'] = data['player_team_name']\n",
    "    data_adv['map'] = data['map']\n",
    "    data_adv = data_adv.drop(['team_A_score_Count','team_B_score_Count'], axis = 1)\n",
    "    data_adv = data_adv.groupby(['match_id', 'player_team_name', 'player_team_opponent','map']).mean()\n",
    "    data_adv = pd.DataFrame(data_adv)\n",
    "    data_adv = data_adv.reset_index()\n",
    "    data_adv = data_adv.apply(pd.to_numeric, errors='ignore')\n",
    "    return data_adv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../scrapped_data/esl_teams.pkl', 'rb') as f: \n",
    "     d = pkl.load(f)\n",
    "\n",
    "big_data = process_scrapped(d)\n",
    "overview, big_data = big_data\n",
    "\n",
    "data = combine_dfs(big_data, overview)\n",
    "data.to_pickle(\"johns_dataset.pkl\")\n",
    "\n",
    "#add a date\n",
    "for idx, row in overview.iterrows():\n",
    "    series_id = row.id\n",
    "    date = row.date\n",
    "    data.loc[data.series_id == series_id, 'date'] = date\n",
    "\n",
    "# sort dates    \n",
    "data = data.sort_values('date')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_pickle('player_rows.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_fwa_dr_columns(data, col_list):  # first k , awp, who, divided by rounds \n",
    "    columns = pd.Series(data.columns)\n",
    "    for a in col_list:\n",
    "        col = columns[columns.str.contains(a)]\n",
    "        data[a+'_sum_dr'] = data[col].convert_objects(convert_numeric = True).sum(axis = 1) / (data['team_A_score'] + data['team_B_score'])\n",
    "    r = data.loc[:, data.columns != 'date'].apply(pd.to_numeric, errors='ignore')\n",
    "    r['date'] = data.date\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#profiling the aggregation steps\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "with open('../scrapped_data/esl_teams.pkl', 'rb') as f: \n",
    "     d = pkl.load(f)\n",
    "\n",
    "big_data = process_scrapped(d)\n",
    "overview, big_data = big_data\n",
    "\n",
    "cProfile.run(\"data = combine_dfs(big_data, overview)\", 'processing_results')\n",
    "\n",
    "results = pstats.Stats('processing_results')\n",
    "results.sort_stats('cumulative').print_stats(10)\n",
    "\n",
    "\"\"\"\n",
    "test_slice = data.loc[data.date==data.date.min(),:]\n",
    "cProfile.run('process_slice(test_slice, col_list)')\n",
    "cProfile.run('create_fwa_dr_columns(test_slice, col_list)', 'profile_results')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../scrapped_data/esl_teams.pkl', 'rb') as f: \n",
    "     d = pkl.load(f)\n",
    "\n",
    "big_data = process_scrapped(d)\n",
    "overview, big_data = big_data\n",
    "\n",
    "def combine_dfs(big_data, overview):\n",
    "    first=True\n",
    "    cols = ['map','round_num','half','match_id','series_id','ending','CT','T','side_winner','winner','team_A','team_B','team_A_score','team_B_score','match_num','team_players','K-D','+/-','ADR','KAST','Rating2.0','nicknames']\n",
    "    dfs = []\n",
    "    for idx, series_data in big_data.iteritems():\n",
    "        series_data_m = merge_matches(series_data)\n",
    "        series_data_m[\"date\"] = overview.loc[overview.id == idx, 'date']\n",
    "        series_data_mo = merge_overview(series_data_m, series_data)\n",
    "        series_data_mos = merge_scoreboards(series_data_mo, series_data)\n",
    "        return series_data_mos, series_data\n",
    "        series_data_mosm = match_data_board_changer(series_data_mos, series_data)\n",
    "        dfs.append(series_data_mosm)    \n",
    "        new_cols = list(set(series_data_mosm.columns) -set(cols))\n",
    "        cols += new_cols\n",
    "    data = pd.concat(dfs)\n",
    "    data = data.loc[:,cols]\n",
    "    data = data.reset_index()\n",
    "    return data\n",
    "\n",
    "\n",
    "series_data_mos, series_data = combine_dfs(big_data, overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         95706 function calls (94263 primitive calls) in 0.088 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.001    0.001    0.088    0.088 <ipython-input-88-e1af2b42fd6e>:70(match_data_board_changer)\n",
      "        1    0.000    0.000    0.088    0.088 <string>:1(<module>)\n",
      "      349    0.000    0.000    0.000    0.000 __init__.py:189(iteritems)\n",
      "        3    0.000    0.000    0.002    0.001 _decorators.py:125(wrapper)\n",
      "        3    0.000    0.000    0.000    0.000 _methods.py:34(_prod)\n",
      "      284    0.000    0.000    0.001    0.000 _methods.py:37(_any)\n",
      "      208    0.000    0.000    0.001    0.000 _methods.py:40(_all)\n",
      "       45    0.000    0.000    0.000    0.000 _validators.py:221(validate_bool_kwarg)\n",
      "        3    0.000    0.000    0.000    0.000 _validators.py:230(validate_axis_style_args)\n",
      "      366    0.000    0.000    0.000    0.000 _weakrefset.py:70(__contains__)\n",
      "      365    0.000    0.000    0.001    0.000 abc.py:128(__instancecheck__)\n",
      "       30    0.000    0.000    0.001    0.000 accessor.py:50(__get__)\n",
      "       91    0.000    0.000    0.000    0.000 algorithms.py:1254(_get_take_nd_function)\n",
      "       91    0.001    0.000    0.004    0.000 algorithms.py:1287(take_nd)\n",
      "        3    0.000    0.000    0.000    0.000 api.py:103(_sanitize_and_check)\n",
      "        3    0.000    0.000    0.001    0.000 api.py:35(_get_objs_combined_axis)\n",
      "        3    0.000    0.000    0.001    0.000 api.py:45(_get_combined_index)\n",
      "        3    0.000    0.000    0.001    0.000 api.py:61(_union_indexes)\n",
      "        3    0.000    0.000    0.000    0.000 api.py:72(_unique_indices)\n",
      "        6    0.000    0.000    0.000    0.000 api.py:73(conv)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:1085(_assert_can_do_setop)\n",
      "        6    0.000    0.000    0.000    0.000 base.py:1108(nlevels)\n",
      "       15    0.000    0.000    0.000    0.000 base.py:1112(_get_names)\n",
      "       15    0.000    0.000    0.000    0.000 base.py:1115(_set_names)\n",
      "       15    0.000    0.000    0.000    0.000 base.py:1123(set_names)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:1149(duplicated)\n",
      "        4    0.000    0.000    0.000    0.000 base.py:1241(is_monotonic)\n",
      "        4    0.000    0.000    0.000    0.000 base.py:1246(is_monotonic_increasing)\n",
      "       86    0.000    0.000    0.000    0.000 base.py:1315(is_unique)\n",
      "       20    0.000    0.000    0.000    0.000 base.py:1324(is_boolean)\n",
      "       30    0.000    0.000    0.000    0.000 base.py:140(_freeze)\n",
      "       90    0.000    0.000    0.000    0.000 base.py:145(__setattr__)\n",
      "       36    0.000    0.000    0.000    0.000 base.py:1587(_cleanup)\n",
      "      176    0.000    0.000    0.001    0.000 base.py:1594(_engine)\n",
      "      157    0.000    0.000    0.001    0.000 base.py:1597(<lambda>)\n",
      "       39    0.000    0.000    0.000    0.000 base.py:1623(inferred_type)\n",
      "       45    0.000    0.000    0.000    0.000 base.py:1635(is_all_dates)\n",
      "      186    0.001    0.000    0.002    0.000 base.py:1692(__contains__)\n",
      "       37    0.000    0.000    0.000    0.000 base.py:1712(contains)\n",
      "      108    0.000    0.000    0.001    0.000 base.py:1726(__getitem__)\n",
      "        6    0.000    0.000    0.001    0.000 base.py:1760(append)\n",
      "        6    0.000    0.000    0.001    0.000 base.py:1789(_concat)\n",
      "        6    0.000    0.000    0.000    0.000 base.py:1797(_concat_same_dtype)\n",
      "  235/181    0.003    0.000    0.011    0.000 base.py:181(__new__)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:1825(take)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:1843(_assert_take_fillable)\n",
      "       68    0.000    0.000    0.002    0.000 base.py:2021(equals)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:2041(identical)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:2272(_wrap_union_result)\n",
      "        3    0.000    0.000    0.001    0.000 base.py:2276(intersection)\n",
      "      277    0.000    0.000    0.001    0.000 base.py:2518(get_loc)\n",
      "       20    0.000    0.000    0.001    0.000 base.py:2662(get_indexer)\n",
      "       20    0.000    0.000    0.000    0.000 base.py:2829(_maybe_promote)\n",
      "        9    0.000    0.000    0.000    0.000 base.py:2927(_can_reindex)\n",
      "       15    0.000    0.000    0.001    0.000 base.py:2946(reindex)\n",
      "       37    0.000    0.000    0.000    0.000 base.py:3467(_maybe_cast_indexer)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:3695(delete)\n",
      "       37    0.000    0.000    0.007    0.000 base.py:3705(insert)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:3724(drop)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:3757(duplicated)\n",
      "      253    0.001    0.000    0.001    0.000 base.py:396(_simple_new)\n",
      "       36    0.000    0.000    0.002    0.000 base.py:4115(_ensure_index_from_sequences)\n",
      "      597    0.000    0.000    0.001    0.000 base.py:4155(_ensure_index)\n",
      "       15    0.000    0.000    0.000    0.000 base.py:4222(_ensure_has_len)\n",
      "      102    0.000    0.000    0.001    0.000 base.py:433(_shallow_copy)\n",
      "       43    0.000    0.000    0.003    0.000 base.py:441(_shallow_copy_with_infer)\n",
      "       68    0.000    0.000    0.000    0.000 base.py:531(is_)\n",
      "      349    0.000    0.000    0.000    0.000 base.py:551(_reset_identity)\n",
      "     1246    0.000    0.000    0.001    0.000 base.py:557(__len__)\n",
      "       49    0.000    0.000    0.000    0.000 base.py:563(__array__)\n",
      "      121    0.000    0.000    0.000    0.000 base.py:578(dtype)\n",
      "      567    0.000    0.000    0.001    0.000 base.py:588(values)\n",
      "      136    0.000    0.000    0.000    0.000 base.py:593(get_values)\n",
      "        6    0.000    0.000    0.000    0.000 base.py:707(ndim)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:717(_coerce_to_ndarray)\n",
      "      188    0.000    0.000    0.000    0.000 base.py:733(_get_attributes_dict)\n",
      "       72    0.000    0.000    0.001    0.000 base.py:737(view)\n",
      "       37    0.000    0.000    0.004    0.000 base.py:749(_coerce_scalar_to_index)\n",
      "      283    0.000    0.000    0.001    0.000 base.py:762(_values)\n",
      "       12    0.000    0.000    0.001    0.000 base.py:786(copy)\n",
      "       12    0.000    0.000    0.000    0.000 base.py:799(tolist)\n",
      "       12    0.000    0.000    0.000    0.000 base.py:809(_validate_names)\n",
      "        6    0.000    0.000    0.000    0.000 base.py:817(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 cast.py:1099(cast_scalar_to_array)\n",
      "       86    0.000    0.000    0.001    0.000 cast.py:252(maybe_promote)\n",
      "        1    0.000    0.000    0.000    0.000 cast.py:354(infer_dtype_from_scalar)\n",
      "       60    0.000    0.000    0.000    0.000 cast.py:826(maybe_castable)\n",
      "      144    0.001    0.000    0.003    0.000 cast.py:838(maybe_infer_to_datetimelike)\n",
      "      121    0.001    0.000    0.003    0.000 cast.py:935(maybe_cast_to_datetime)\n",
      "      188    0.000    0.000    0.001    0.000 common.py:1009(is_datetime64_any_dtype)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:1136(is_datetime_or_timedelta_dtype)\n",
      "      255    0.000    0.000    0.001    0.000 common.py:118(is_sparse)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:1371(needs_i8_conversion)\n",
      "        8    0.000    0.000    0.000    0.000 common.py:1412(is_numeric_dtype)\n",
      "       86    0.000    0.000    0.000    0.000 common.py:1456(is_string_like_dtype)\n",
      "      195    0.000    0.000    0.000    0.000 common.py:1493(is_float_dtype)\n",
      "      148    0.000    0.000    0.001    0.000 common.py:1545(is_bool_dtype)\n",
      "      134    0.000    0.000    0.001    0.000 common.py:1596(is_extension_type)\n",
      "      285    0.000    0.000    0.000    0.000 common.py:1722(_get_dtype)\n",
      "     1627    0.002    0.000    0.003    0.000 common.py:1773(_get_dtype_type)\n",
      "       38    0.000    0.000    0.000    0.000 common.py:184(is_bool_indexer)\n",
      "      431    0.000    0.000    0.001    0.000 common.py:191(is_categorical)\n",
      "       30    0.000    0.000    0.001    0.000 common.py:207(_default_index)\n",
      "      754    0.000    0.000    0.002    0.000 common.py:223(is_datetimetz)\n",
      "        3    0.000    0.000    0.000    0.000 common.py:225(_not_none)\n",
      "        9    0.000    0.000    0.000    0.000 common.py:227(<genexpr>)\n",
      "       30    0.000    0.000    0.000    0.000 common.py:238(_all_none)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:246(_any_not_none)\n",
      "        3    0.000    0.000    0.000    0.000 common.py:262(_count_not_none)\n",
      "        9    0.000    0.000    0.000    0.000 common.py:264(<genexpr>)\n",
      "        7    0.000    0.000    0.000    0.000 common.py:267(_try_sort)\n",
      "      267    0.000    0.000    0.001    0.000 common.py:297(is_datetime64_dtype)\n",
      "      964    0.000    0.000    0.001    0.000 common.py:334(is_datetime64tz_dtype)\n",
      "      266    0.000    0.000    0.001    0.000 common.py:372(is_timedelta64_dtype)\n",
      "      205    0.001    0.000    0.002    0.000 common.py:375(_asarray_tuplesafe)\n",
      "        3    0.000    0.000    0.000    0.000 common.py:407(_index_labels_to_array)\n",
      "      129    0.000    0.000    0.000    0.000 common.py:409(is_period_dtype)\n",
      "        9    0.000    0.000    0.000    0.000 common.py:422(_maybe_make_list)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:428(is_null_slice)\n",
      "      382    0.000    0.000    0.001    0.000 common.py:442(is_interval_dtype)\n",
      "      143    0.000    0.000    0.000    0.000 common.py:464(_apply_if_callable)\n",
      "     1245    0.001    0.000    0.002    0.000 common.py:478(is_categorical_dtype)\n",
      "      129    0.000    0.000    0.001    0.000 common.py:511(is_string_dtype)\n",
      "       12    0.000    0.000    0.000    0.000 common.py:612(is_datetimelike)\n",
      "        3    0.000    0.000    0.000    0.000 common.py:655(_get_distinct_objs)\n",
      "       35    0.000    0.000    0.000    0.000 common.py:657(is_dtype_equal)\n",
      "       37    0.000    0.000    0.000    0.000 common.py:777(is_integer_dtype)\n",
      "      151    0.000    0.000    0.000    0.000 common.py:824(is_signed_integer_dtype)\n",
      "      472    0.000    0.000    0.001    0.000 common.py:85(is_object_dtype)\n",
      "      148    0.000    0.000    0.000    0.000 common.py:873(is_unsigned_integer_dtype)\n",
      "       11    0.000    0.000    0.000    0.000 common.py:961(is_int_or_datetime_dtype)\n",
      "       24    0.000    0.000    0.001    0.000 concat.py:102(_concat_compat)\n",
      "       48    0.000    0.000    0.000    0.000 concat.py:121(is_nonempty)\n",
      "       48    0.000    0.000    0.000    0.000 concat.py:138(<genexpr>)\n",
      "       48    0.000    0.000    0.000    0.000 concat.py:139(<genexpr>)\n",
      "        3    0.000    0.000    0.009    0.003 concat.py:21(concat)\n",
      "        3    0.000    0.000    0.003    0.001 concat.py:221(__init__)\n",
      "       30    0.000    0.000    0.001    0.000 concat.py:25(get_dtype_kinds)\n",
      "        3    0.000    0.000    0.006    0.002 concat.py:365(get_result)\n",
      "        3    0.000    0.000    0.000    0.000 concat.py:416(_get_result_dim)\n",
      "        3    0.000    0.000    0.001    0.000 concat.py:422(_get_new_axes)\n",
      "        3    0.000    0.000    0.001    0.000 concat.py:446(_get_comb_axis)\n",
      "        3    0.000    0.000    0.000    0.000 concat.py:456(_get_concat_axis)\n",
      "        6    0.000    0.000    0.000    0.000 concat.py:470(_concat_index_asobject)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        3    0.000    0.000    0.000    0.000 concat.py:504(_maybe_check_integrity)\n",
      "        3    0.000    0.000    0.000    0.000 concat.py:512(_concat_indexes)\n",
      "        3    0.000    0.000    0.000    0.000 concat.py:89(_get_frame_result_type)\n",
      "       27    0.000    0.000    0.000    0.000 concat.py:95(<genexpr>)\n",
      "        9    0.000    0.000    0.000    0.000 copy.py:113(_copy_with_constructor)\n",
      "     24/6    0.000    0.000    0.000    0.000 copy.py:145(deepcopy)\n",
      "        6    0.000    0.000    0.000    0.000 copy.py:198(_deepcopy_atomic)\n",
      "        6    0.000    0.000    0.000    0.000 copy.py:226(_deepcopy_list)\n",
      "        6    0.000    0.000    0.000    0.000 copy.py:234(_deepcopy_tuple)\n",
      "       24    0.000    0.000    0.000    0.000 copy.py:267(_keep_alive)\n",
      "        6    0.000    0.000    0.000    0.000 copy.py:306(_reconstruct)\n",
      "        9    0.000    0.000    0.000    0.000 copy.py:66(copy)\n",
      "       57    0.000    0.000    0.000    0.000 dtypes.py:269(construct_from_string)\n",
      "        3    0.000    0.000    0.000    0.000 dtypes.py:372(__new__)\n",
      "        3    0.000    0.000    0.000    0.000 dtypes.py:430(construct_from_string)\n",
      "      129    0.000    0.000    0.000    0.000 dtypes.py:556(is_dtype)\n",
      "       54    0.000    0.000    0.000    0.000 dtypes.py:645(construct_from_string)\n",
      "      382    0.000    0.000    0.001    0.000 dtypes.py:678(is_dtype)\n",
      "     2571    0.002    0.000    0.003    0.000 dtypes.py:85(is_dtype)\n",
      "       18    0.000    0.000    0.003    0.000 frame.py:1906(transpose)\n",
      "      104    0.000    0.000    0.009    0.000 frame.py:2115(__getitem__)\n",
      "      104    0.000    0.000    0.007    0.000 frame.py:2141(_getitem_column)\n",
      "      102    0.000    0.000    0.003    0.000 frame.py:2493(_box_item_values)\n",
      "      102    0.000    0.000    0.003    0.000 frame.py:2500(_box_col_values)\n",
      "       37    0.000    0.000    0.016    0.000 frame.py:2505(__setitem__)\n",
      "       37    0.000    0.000    0.001    0.000 frame.py:2556(_ensure_valid_index)\n",
      "       37    0.000    0.000    0.015    0.000 frame.py:2573(_set_item)\n",
      "       37    0.000    0.000    0.003    0.000 frame.py:2697(_sanitize_column)\n",
      "       30    0.000    0.000    0.001    0.000 frame.py:2717(reindexer)\n",
      "        3    0.000    0.000    0.001    0.000 frame.py:2858(_reindex_axes)\n",
      "        3    0.000    0.000    0.001    0.000 frame.py:2883(_reindex_columns)\n",
      "        3    0.000    0.000    0.002    0.001 frame.py:2921(reindex)\n",
      "       61    0.000    0.000    0.000    0.000 frame.py:303(_constructor)\n",
      "       36    0.000    0.000    0.020    0.001 frame.py:3042(set_index)\n",
      "      101    0.001    0.000    0.019    0.000 frame.py:316(__init__)\n",
      "        7    0.000    0.000    0.003    0.000 frame.py:408(_init_dict)\n",
      "       18    0.000    0.000    0.002    0.000 frame.py:463(_init_ndarray)\n",
      "       18    0.000    0.000    0.000    0.000 frame.py:480(_get_axes)\n",
      "        3    0.000    0.000    0.009    0.003 frame.py:5073(append)\n",
      "        4    0.000    0.000    0.000    0.000 frame.py:535(axes)\n",
      "        6    0.000    0.000    0.000    0.000 frame.py:543(shape)\n",
      "       37    0.000    0.000    0.011    0.000 frame.py:6156(_arrays_to_mgr)\n",
      "        7    0.000    0.000    0.001    0.000 frame.py:6176(extract_index)\n",
      "       18    0.000    0.000    0.000    0.000 frame.py:6228(_prep_ndarray)\n",
      "       30    0.000    0.000    0.004    0.000 frame.py:6262(_to_arrays)\n",
      "       30    0.000    0.000    0.004    0.000 frame.py:6356(_list_to_arrays)\n",
      "       30    0.000    0.000    0.004    0.000 frame.py:6413(_convert_object_array)\n",
      "       60    0.000    0.000    0.003    0.000 frame.py:6423(convert)\n",
      "       37    0.000    0.000    0.003    0.000 frame.py:6452(_homogenize)\n",
      "       41    0.000    0.000    0.000    0.000 frame.py:817(__len__)\n",
      "       74    0.000    0.000    0.000    0.000 fromnumeric.py:1380(ravel)\n",
      "        3    0.000    0.000    0.000    0.000 fromnumeric.py:2408(prod)\n",
      "        9    0.000    0.000    0.000    0.000 fromnumeric.py:55(_wrapfunc)\n",
      "        9    0.000    0.000    0.000    0.000 fromnumeric.py:826(argsort)\n",
      "       15    0.000    0.000    0.000    0.000 frozen.py:38(__getitem__)\n",
      "        6    0.000    0.000    0.000    0.000 frozen.py:61(__reduce__)\n",
      "       18    0.000    0.000    0.000    0.000 function.py:267(validate_transpose_for_generic)\n",
      "       36    0.000    0.000    0.000    0.000 function.py:38(__call__)\n",
      "       75    0.001    0.000    0.002    0.000 function_base.py:4689(delete)\n",
      "       74    0.000    0.000    0.001    0.000 function_base.py:5100(append)\n",
      "        8    0.000    0.000    0.000    0.000 generic.py:1073(__contains__)\n",
      "      209    0.000    0.000    0.000    0.000 generic.py:120(__init__)\n",
      "       46    0.000    0.000    0.000    0.000 generic.py:162(_init_mgr)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:1804(_indexer)\n",
      "      104    0.000    0.000    0.007    0.000 generic.py:1837(_get_item_cache)\n",
      "      102    0.000    0.000    0.000    0.000 generic.py:1851(_set_as_cached)\n",
      "       82    0.000    0.000    0.000    0.000 generic.py:1931(_clear_item_cache)\n",
      "       37    0.000    0.000    0.010    0.000 generic.py:1953(_set_item)\n",
      "       37    0.000    0.000    0.000    0.000 generic.py:1987(_check_setitem_copy)\n",
      "       36    0.000    0.000    0.010    0.000 generic.py:2070(__delitem__)\n",
      "        1    0.000    0.000    0.001    0.001 generic.py:2141(_take)\n",
      "        3    0.000    0.000    0.002    0.001 generic.py:2448(drop)\n",
      "        3    0.000    0.000    0.002    0.001 generic.py:2537(_drop_axis)\n",
      "       18    0.000    0.000    0.000    0.000 generic.py:285(_construct_axes_dict_from)\n",
      "        3    0.000    0.000    0.002    0.001 generic.py:2981(reindex)\n",
      "       21    0.000    0.000    0.000    0.000 generic.py:299(_construct_axes_from_arguments)\n",
      "        3    0.000    0.000    0.000    0.000 generic.py:3045(_needs_reindex_multi)\n",
      "        3    0.000    0.000    0.001    0.000 generic.py:3124(_reindex_with_indexers)\n",
      "        3    0.000    0.000    0.000    0.000 generic.py:334(_from_axes)\n",
      "       49    0.000    0.000    0.000    0.000 generic.py:346(_get_axis_number)\n",
      "       67    0.000    0.000    0.000    0.000 generic.py:3583(__finalize__)\n",
      "      100    0.000    0.000    0.000    0.000 generic.py:359(_get_axis_name)\n",
      "      108    0.000    0.000    0.000    0.000 generic.py:3600(__getattr__)\n",
      "      383    0.001    0.000    0.002    0.000 generic.py:3616(__setattr__)\n",
      "       28    0.000    0.000    0.002    0.000 generic.py:3661(_protect_consolidate)\n",
      "       28    0.000    0.000    0.002    0.000 generic.py:3671(_consolidate_inplace)\n",
      "       28    0.000    0.000    0.002    0.000 generic.py:3674(f)\n",
      "        6    0.000    0.000    0.002    0.000 generic.py:3679(_consolidate)\n",
      "       55    0.000    0.000    0.000    0.000 generic.py:372(_get_axis)\n",
      "       18    0.000    0.000    0.000    0.000 generic.py:3753(as_matrix)\n",
      "        7    0.000    0.000    0.000    0.000 generic.py:376(_get_block_manager_axis)\n",
      "       18    0.000    0.000    0.000    0.000 generic.py:3795(values)\n",
      "       36    0.000    0.000    0.004    0.000 generic.py:4007(copy)\n",
      "        8    0.000    0.000    0.000    0.000 generic.py:420(_info_axis)\n",
      "       18    0.000    0.000    0.000    0.000 generic.py:440(ndim)\n",
      "       36    0.000    0.000    0.000    0.000 generic.py:558(_set_axis)\n",
      "       18    0.000    0.000    0.003    0.000 generic.py:582(transpose)\n",
      "     3075    0.001    0.000    0.003    0.000 generic.py:7(_check)\n",
      "       36    0.001    0.000    0.001    0.000 index_tricks.py:247(__getitem__)\n",
      "        1    0.000    0.000    0.001    0.001 indexing.py:1358(__getitem__)\n",
      "        3    0.000    0.000    0.000    0.000 indexing.py:1360(<genexpr>)\n",
      "        1    0.000    0.000    0.001    0.001 indexing.py:1384(_getbool_axis)\n",
      "        2    0.000    0.000    0.000    0.000 indexing.py:1443(_has_valid_type)\n",
      "        1    0.000    0.000    0.000    0.000 indexing.py:1518(_is_scalar_access)\n",
      "        1    0.000    0.000    0.000    0.000 indexing.py:1548(_get_partial_string_timestamp_match_key)\n",
      "        1    0.000    0.000    0.001    0.001 indexing.py:1572(_getitem_axis)\n",
      "       37    0.000    0.000    0.001    0.000 indexing.py:1975(convert_to_index_sliceable)\n",
      "        1    0.000    0.000    0.000    0.000 indexing.py:199(_has_valid_tuple)\n",
      "        1    0.000    0.000    0.000    0.000 indexing.py:2012(check_bool_indexer)\n",
      "        1    0.000    0.000    0.000    0.000 indexing.py:2065(maybe_convert_indices)\n",
      "        2    0.000    0.000    0.000    0.000 indexing.py:2137(is_list_like_indexer)\n",
      "        2    0.000    0.000    0.000    0.000 indexing.py:2143(is_label_like)\n",
      "        1    0.000    0.000    0.000    0.000 indexing.py:223(_is_nested_tuple_indexer)\n",
      "        1    0.000    0.000    0.001    0.001 indexing.py:856(_getitem_tuple)\n",
      "        1    0.000    0.000    0.000    0.000 indexing.py:882(_multi_take_opportunity)\n",
      "        2    0.000    0.000    0.000    0.000 indexing.py:889(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 indexing.py:93(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 indexing.py:963(_getitem_lowerdim)\n",
      "      365    0.000    0.000    0.001    0.000 inference.py:234(is_list_like)\n",
      "       30    0.000    0.000    0.000    0.000 inference.py:338(is_named_tuple)\n",
      "      108    0.000    0.000    0.000    0.000 inference.py:365(is_hashable)\n",
      "        1    0.000    0.000    0.000    0.000 inference.py:397(is_sequence)\n",
      "      295    0.001    0.000    0.002    0.000 internals.py:107(__init__)\n",
      "        5    0.000    0.000    0.000    0.000 internals.py:1200(take_nd)\n",
      "      126    0.000    0.000    0.000    0.000 internals.py:122(_consolidate_key)\n",
      "       30    0.000    0.000    0.000    0.000 internals.py:155(external_values)\n",
      "       74    0.000    0.000    0.000    0.000 internals.py:159(internal_values)\n",
      "       78    0.000    0.000    0.000    0.000 internals.py:169(get_values)\n",
      "        8    0.000    0.000    0.000    0.000 internals.py:185(fill_value)\n",
      "     1094    0.000    0.000    0.000    0.000 internals.py:189(mgr_locs)\n",
      "      287    0.001    0.000    0.003    0.000 internals.py:2076(__init__)\n",
      "       55    0.000    0.000    0.000    0.000 internals.py:2084(is_bool)\n",
      "      143    0.000    0.000    0.001    0.000 internals.py:218(make_block_same_class)\n",
      "      367    0.000    0.000    0.001    0.000 internals.py:226(mgr_locs)\n",
      "      295    0.001    0.000    0.005    0.000 internals.py:2921(make_block)\n",
      "      174    0.000    0.000    0.000    0.000 internals.py:299(shape)\n",
      "      116    0.001    0.000    0.006    0.000 internals.py:3017(__init__)\n",
      "      492    0.001    0.000    0.002    0.000 internals.py:3058(shape)\n",
      "     1476    0.000    0.000    0.002    0.000 internals.py:3060(<genexpr>)\n",
      "      342    0.000    0.000    0.000    0.000 internals.py:3062(ndim)\n",
      "       36    0.000    0.000    0.000    0.000 internals.py:3066(set_axis)\n",
      "      569    0.000    0.000    0.000    0.000 internals.py:307(dtype)\n",
      "       28    0.000    0.000    0.000    0.000 internals.py:3102(_is_single_block)\n",
      "      257    0.000    0.000    0.000    0.000 internals.py:311(ftype)\n",
      "      161    0.002    0.000    0.006    0.000 internals.py:3114(_rebuild_blknos_and_blklocs)\n",
      "      600    0.000    0.000    0.000    0.000 internals.py:3135(_get_items)\n",
      "       53    0.000    0.000    0.000    0.000 internals.py:3224(__len__)\n",
      "       80    0.000    0.000    0.001    0.000 internals.py:3239(_verify_integrity)\n",
      "      254    0.000    0.000    0.000    0.000 internals.py:3241(<genexpr>)\n",
      "       36    0.000    0.000    0.002    0.000 internals.py:3251(apply)\n",
      "       36    0.000    0.000    0.000    0.000 internals.py:3310(<genexpr>)\n",
      "      102    0.000    0.000    0.000    0.000 internals.py:341(iget)\n",
      "      175    0.000    0.000    0.000    0.000 internals.py:3524(is_consolidated)\n",
      "      123    0.000    0.000    0.001    0.000 internals.py:3532(_consolidate_check)\n",
      "       36    0.000    0.000    0.003    0.000 internals.py:354(delete)\n",
      "       36    0.000    0.000    0.003    0.000 internals.py:3639(copy)\n",
      "       72    0.000    0.000    0.001    0.000 internals.py:3659(<lambda>)\n",
      "       18    0.000    0.000    0.000    0.000 internals.py:3666(as_matrix)\n",
      "       28    0.000    0.000    0.002    0.000 internals.py:3813(consolidate)\n",
      "      147    0.000    0.000    0.001    0.000 internals.py:3829(_consolidate_inplace)\n",
      "      102    0.000    0.000    0.003    0.000 internals.py:3836(get)\n",
      "      102    0.001    0.000    0.002    0.000 internals.py:3865(iget)\n",
      "       36    0.001    0.000    0.009    0.000 internals.py:3898(delete)\n",
      "       72    0.000    0.000    0.000    0.000 internals.py:3931(<genexpr>)\n",
      "       37    0.000    0.000    0.010    0.000 internals.py:3936(set)\n",
      "       37    0.001    0.000    0.009    0.000 internals.py:4048(insert)\n",
      "        6    0.000    0.000    0.001    0.000 internals.py:4101(reindex_axis)\n",
      "       10    0.000    0.000    0.001    0.000 internals.py:4113(reindex_indexer)\n",
      "        4    0.000    0.000    0.001    0.000 internals.py:4156(_slice_take_blocks_ax0)\n",
      "        1    0.000    0.000    0.000    0.000 internals.py:4243(take)\n",
      "      102    0.000    0.000    0.000    0.000 internals.py:4363(__init__)\n",
      "      224    0.000    0.000    0.000    0.000 internals.py:4409(_block)\n",
      "      120    0.000    0.000    0.000    0.000 internals.py:4479(dtype)\n",
      "       30    0.000    0.000    0.000    0.000 internals.py:4503(external_values)\n",
      "       74    0.000    0.000    0.000    0.000 internals.py:4506(internal_values)\n",
      "       18    0.000    0.000    0.001    0.000 internals.py:4611(create_block_manager_from_blocks)\n",
      "       37    0.000    0.000    0.007    0.000 internals.py:4634(create_block_manager_from_arrays)\n",
      "       37    0.001    0.000    0.005    0.000 internals.py:4645(form_blocks)\n",
      "       30    0.000    0.000    0.002    0.000 internals.py:4755(_simple_blockify)\n",
      "       30    0.000    0.000    0.000    0.000 internals.py:4801(_stack_arrays)\n",
      "       60    0.000    0.000    0.000    0.000 internals.py:4804(_asarray_compat)\n",
      "       30    0.000    0.000    0.000    0.000 internals.py:4810(_shape_compat)\n",
      "        9    0.000    0.000    0.001    0.000 internals.py:4841(_consolidate)\n",
      "      126    0.000    0.000    0.000    0.000 internals.py:4847(<lambda>)\n",
      "       10    0.000    0.000    0.001    0.000 internals.py:4858(_merge_blocks)\n",
      "       46    0.000    0.000    0.000    0.000 internals.py:4885(_extend_blocks)\n",
      "        9    0.000    0.000    0.000    0.000 internals.py:4911(_vstack)\n",
      "       91    0.000    0.000    0.000    0.000 internals.py:4990(_get_blkno_placements)\n",
      "        3    0.000    0.000    0.001    0.000 internals.py:5013(items_overlap_with_suffix)\n",
      "        6    0.000    0.000    0.012    0.002 internals.py:5170(concatenate_block_managers)\n",
      "       58    0.000    0.000    0.002    0.000 internals.py:5210(is_uniform_join_units)\n",
      "       58    0.000    0.000    0.002    0.000 internals.py:5230(get_empty_dtype_and_na)\n",
      "       58    0.000    0.000    0.007    0.000 internals.py:5320(concatenate_join_units)\n",
      "       12    0.000    0.000    0.001    0.000 internals.py:5345(get_mgr_concatenation_plan)\n",
      "       64    0.000    0.000    0.000    0.000 internals.py:5424(combine_concat_plans)\n",
      "       48    0.000    0.000    0.000    0.000 internals.py:5449(_next_or_none)\n",
      "        6    0.000    0.000    0.000    0.000 internals.py:5487(trim_join_unit)\n",
      "       82    0.000    0.000    0.000    0.000 internals.py:5518(__init__)\n",
      "       61    0.000    0.000    0.001    0.000 internals.py:5530(needs_filling)\n",
      "       61    0.000    0.000    0.001    0.000 internals.py:5539(dtype)\n",
      "       82    0.000    0.000    0.003    0.000 internals.py:5550(is_na)\n",
      "       82    0.000    0.000    0.003    0.000 internals.py:5579(get_reindexed_values)\n",
      "       73    0.000    0.000    0.002    0.000 internals.py:5637(_fast_count_smallints)\n",
      "        4    0.000    0.000    0.000    0.000 internals.py:5648(_preprocess_slice_or_indexer)\n",
      "       36    0.000    0.000    0.000    0.000 internals.py:732(copy)\n",
      "        3    0.000    0.000    0.001    0.000 merge.py:1024(_get_join_indexers)\n",
      "        7    0.000    0.000    0.000    0.000 merge.py:1457(_factorize_keys)\n",
      "        3    0.000    0.000    0.000    0.000 merge.py:1520(_get_join_keys)\n",
      "        3    0.000    0.000    0.000    0.000 merge.py:1523(<lambda>)\n",
      "        4    0.000    0.000    0.000    0.000 merge.py:1550(_should_fill)\n",
      "        6    0.000    0.000    0.000    0.000 merge.py:1557(_any)\n",
      "        3    0.000    0.000    0.011    0.004 merge.py:47(merge)\n",
      "        3    0.000    0.000    0.003    0.001 merge.py:505(__init__)\n",
      "        3    0.000    0.000    0.008    0.003 merge.py:577(get_result)\n",
      "        3    0.000    0.000    0.000    0.000 merge.py:648(_maybe_add_join_keys)\n",
      "        3    0.000    0.000    0.001    0.000 merge.py:722(_get_join_indexers)\n",
      "        3    0.000    0.000    0.001    0.000 merge.py:729(_get_join_info)\n",
      "        3    0.000    0.000    0.003    0.001 merge.py:769(_get_merge_keys)\n",
      "        4    0.000    0.000    0.000    0.000 merge.py:790(<lambda>)\n",
      "        4    0.000    0.000    0.000    0.000 merge.py:792(<lambda>)\n",
      "        3    0.000    0.000    0.000    0.000 merge.py:880(_maybe_coerce_merge_keys)\n",
      "        3    0.000    0.000    0.000    0.000 merge.py:936(_validate_specification)\n",
      "       88    0.001    0.000    0.002    0.000 missing.py:123(_isna_ndarraylike)\n",
      "       68    0.000    0.000    0.001    0.000 missing.py:255(array_equivalent)\n",
      "      190    0.000    0.000    0.003    0.000 missing.py:26(isna)\n",
      "      190    0.000    0.000    0.003    0.000 missing.py:51(_isna_new)\n",
      "       23    0.000    0.000    0.000    0.000 missing.py:590(clean_reindex_fill_method)\n",
      "       23    0.000    0.000    0.000    0.000 missing.py:73(clean_fill_method)\n",
      "       75    0.000    0.000    0.000    0.000 numeric.py:150(ones)\n",
      "        3    0.000    0.000    0.000    0.000 numeric.py:174(_assert_safe_casting)\n",
      "        2    0.000    0.000    0.000    0.000 numeric.py:2667(seterr)\n",
      "        2    0.000    0.000    0.000    0.000 numeric.py:2767(geterr)\n",
      "        1    0.000    0.000    0.000    0.000 numeric.py:3060(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 numeric.py:3064(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 numeric.py:3069(__exit__)\n",
      "        3    0.000    0.000    0.000    0.000 numeric.py:35(__new__)\n",
      "      682    0.000    0.000    0.001    0.000 numeric.py:463(asarray)\n",
      "      252    0.000    0.000    0.000    0.000 numeric.py:534(asanyarray)\n",
      "       75    0.001    0.000    0.001    0.000 numeric.py:660(require)\n",
      "      150    0.000    0.000    0.000    0.000 numeric.py:729(<genexpr>)\n",
      "       40    0.000    0.000    0.000    0.000 numeric.py:99(is_all_dates)\n",
      "       82    0.000    0.000    0.000    0.000 numerictypes.py:942(_can_coerce_all)\n",
      "       41    0.000    0.000    0.000    0.000 numerictypes.py:964(find_common_type)\n",
      "       96    0.000    0.000    0.000    0.000 range.py:119(_simple_new)\n",
      "       60    0.000    0.000    0.000    0.000 range.py:146(_validate_dtype)\n",
      "       30    0.000    0.000    0.000    0.000 range.py:157(_data)\n",
      "       66    0.000    0.000    0.000    0.000 range.py:165(_get_data_as_items)\n",
      "       60    0.000    0.000    0.000    0.000 range.py:228(is_unique)\n",
      "       36    0.000    0.000    0.000    0.000 range.py:248(_shallow_copy)\n",
      "       30    0.000    0.000    0.000    0.000 range.py:303(equals)\n",
      "      546    0.000    0.000    0.001    0.000 range.py:469(__len__)\n",
      "       90    0.000    0.000    0.000    0.000 range.py:479(__getitem__)\n",
      "       96    0.000    0.000    0.001    0.000 range.py:56(__new__)\n",
      "       60    0.000    0.000    0.000    0.000 range.py:72(_ensure_int)\n",
      "      108    0.001    0.000    0.002    0.000 series.py:155(__init__)\n",
      "      102    0.000    0.000    0.003    0.000 series.py:273(from_array)\n",
      "       30    0.000    0.000    0.000    0.000 series.py:288(_constructor_expanddim)\n",
      "      108    0.000    0.000    0.001    0.000 series.py:300(_set_axis)\n",
      "        6    0.000    0.000    0.000    0.000 series.py:3112(_sanitize_index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       60    0.000    0.000    0.002    0.000 series.py:3136(_sanitize_array)\n",
      "       60    0.000    0.000    0.002    0.000 series.py:3153(_try_cast)\n",
      "      108    0.000    0.000    0.000    0.000 series.py:326(_set_subtyp)\n",
      "      114    0.000    0.000    0.000    0.000 series.py:336(name)\n",
      "      108    0.000    0.000    0.000    0.000 series.py:340(name)\n",
      "      120    0.000    0.000    0.000    0.000 series.py:347(dtype)\n",
      "       30    0.000    0.000    0.000    0.000 series.py:367(values)\n",
      "       74    0.000    0.000    0.000    0.000 series.py:400(_values)\n",
      "       30    0.000    0.000    0.000    0.000 series.py:483(__len__)\n",
      "        9    0.000    0.000    0.000    0.000 shape_base.py:182(vstack)\n",
      "       99    0.000    0.000    0.000    0.000 shape_base.py:63(atleast_2d)\n",
      "        3    0.000    0.000    0.000    0.000 sorting.py:119(is_int64_overflow_possible)\n",
      "       30    0.000    0.000    0.002    0.000 strings.py:1002(str_split)\n",
      "      150    0.000    0.000    0.000    0.000 strings.py:1031(<lambda>)\n",
      "       30    0.000    0.000    0.000    0.000 strings.py:1373(__init__)\n",
      "       30    0.001    0.000    0.015    0.000 strings.py:1394(_wrap_result)\n",
      "      150    0.000    0.000    0.001    0.000 strings.py:1419(cons_row)\n",
      "      180    0.000    0.000    0.000    0.000 strings.py:1428(<genexpr>)\n",
      "       30    0.000    0.000    0.017    0.001 strings.py:1478(split)\n",
      "       30    0.000    0.000    0.002    0.000 strings.py:154(_na_map)\n",
      "       30    0.000    0.000    0.002    0.000 strings.py:159(_map)\n",
      "       30    0.000    0.000    0.001    0.000 strings.py:1897(_make_accessor)\n",
      "      165    0.000    0.000    0.000    0.000 {all}\n",
      "       52    0.000    0.000    0.000    0.000 {any}\n",
      "      349    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x00000000715F61C0}\n",
      "      143    0.000    0.000    0.000    0.000 {callable}\n",
      "       15    0.000    0.000    0.000    0.000 {function __getitem__ at 0x000000000CB94668}\n",
      "4214/4213    0.002    0.000    0.002    0.000 {getattr}\n",
      "     3392    0.001    0.000    0.001    0.000 {hasattr}\n",
      "      331    0.000    0.000    0.000    0.000 {hash}\n",
      "       84    0.000    0.000    0.000    0.000 {id}\n",
      "    19583    0.004    0.000    0.008    0.000 {isinstance}\n",
      "     3863    0.001    0.000    0.001    0.000 {issubclass}\n",
      "        7    0.000    0.000    0.000    0.000 {iter}\n",
      "7829/6459    0.002    0.000    0.003    0.000 {len}\n",
      "      665    0.000    0.000    0.001    0.000 {max}\n",
      "        6    0.000    0.000    0.000    0.000 {method '__reduce_ex__' of 'object' objects}\n",
      "       70    0.000    0.000    0.001    0.000 {method 'add' of 'pandas._libs.lib.BlockPlacement' objects}\n",
      "       72    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "      208    0.000    0.000    0.001    0.000 {method 'all' of 'numpy.ndarray' objects}\n",
      "      248    0.000    0.000    0.001    0.000 {method 'any' of 'numpy.ndarray' objects}\n",
      "      775    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        9    0.000    0.000    0.000    0.000 {method 'argsort' of 'numpy.ndarray' objects}\n",
      "       68    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
      "       82    0.000    0.000    0.000    0.000 {method 'clear' of 'dict' objects}\n",
      "       36    0.000    0.000    0.000    0.000 {method 'clear_mapping' of 'pandas._libs.index.IndexEngine' objects}\n",
      "       73    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
      "       92    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}\n",
      "       36    0.000    0.000    0.000    0.000 {method 'cumsum' of 'numpy.ndarray' objects}\n",
      "       36    0.000    0.000    0.001    0.000 {method 'delete' of 'pandas._libs.lib.BlockPlacement' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "       30    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method 'factorize' of 'pandas._libs.hashtable.Factorizer' objects}\n",
      "        8    0.000    0.000    0.000    0.000 {method 'factorize' of 'pandas._libs.hashtable.Int64Factorizer' objects}\n",
      "      345    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}\n",
      "      461    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'get_count' of 'pandas._libs.hashtable.Factorizer' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'get_count' of 'pandas._libs.hashtable.Int64Factorizer' objects}\n",
      "       20    0.000    0.000    0.000    0.000 {method 'get_indexer' of 'pandas._libs.index.IndexEngine' objects}\n",
      "      314    0.001    0.000    0.001    0.000 {method 'get_loc' of 'pandas._libs.index.IndexEngine' objects}\n",
      "      127    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "      349    0.000    0.000    0.000    0.000 {method 'iteritems' of 'dict' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
      "       75    0.000    0.000    0.000    0.000 {method 'nonzero' of 'numpy.ndarray' objects}\n",
      "      125    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
      "       39    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
      "      374    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "      495    0.001    0.000    0.001    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "       86    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'search' of '_sre.SRE_Pattern' objects}\n",
      "      150    0.000    0.000    0.000    0.000 {method 'split' of 'unicode' objects}\n",
      "      264    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\n",
      "       12    0.000    0.000    0.000    0.000 {method 'tolist' of 'numpy.ndarray' objects}\n",
      "       90    0.000    0.000    0.000    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
      "      166    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
      "       75    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}\n",
      "       64    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
      "      646    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\n",
      "       24    0.000    0.000    0.000    0.000 {min}\n",
      "       51    0.000    0.000    0.000    0.000 {next}\n",
      "      326    0.000    0.000    0.000    0.000 {numpy.core.multiarray.arange}\n",
      "     1397    0.001    0.000    0.001    0.000 {numpy.core.multiarray.array}\n",
      "       36    0.000    0.000    0.000    0.000 {numpy.core.multiarray.bincount}\n",
      "       75    0.000    0.000    0.000    0.000 {numpy.core.multiarray.can_cast}\n",
      "      195    0.000    0.000    0.000    0.000 {numpy.core.multiarray.concatenate}\n",
      "       75    0.000    0.000    0.000    0.000 {numpy.core.multiarray.copyto}\n",
      "      664    0.001    0.000    0.001    0.000 {numpy.core.multiarray.empty}\n",
      "       75    0.000    0.000    0.000    0.000 {numpy.core.multiarray.normalize_axis_index}\n",
      "       37    0.000    0.000    0.000    0.000 {numpy.core.multiarray.zeros}\n",
      "        4    0.000    0.000    0.000    0.000 {numpy.core.umath.geterrobj}\n",
      "        2    0.000    0.000    0.000    0.000 {numpy.core.umath.seterrobj}\n",
      "      115    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_int64}\n",
      "      277    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_object}\n",
      "       26    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_platform_int}\n",
      "       26    0.000    0.000    0.000    0.000 {pandas._libs.algos.take_1d_int64_int64}\n",
      "        2    0.000    0.000    0.000    0.000 {pandas._libs.algos.take_2d_axis0_float64_float64}\n",
      "        1    0.000    0.000    0.000    0.000 {pandas._libs.algos.take_2d_axis0_int32_int32}\n",
      "        1    0.000    0.000    0.000    0.000 {pandas._libs.algos.take_2d_axis0_int64_int64}\n",
      "       47    0.000    0.000    0.000    0.000 {pandas._libs.algos.take_2d_axis0_object_object}\n",
      "        2    0.000    0.000    0.000    0.000 {pandas._libs.algos.take_2d_axis1_int64_int64}\n",
      "       12    0.000    0.000    0.000    0.000 {pandas._libs.algos.take_2d_axis1_object_object}\n",
      "        1    0.000    0.000    0.000    0.000 {pandas._libs.join.inner_join_indexer_object}\n",
      "        3    0.000    0.000    0.000    0.000 {pandas._libs.join.inner_join}\n",
      "       41    0.000    0.000    0.000    0.000 {pandas._libs.lib.array_equivalent_object}\n",
      "      102    0.000    0.000    0.000    0.000 {pandas._libs.lib.checknull}\n",
      "        3    0.000    0.000    0.000    0.000 {pandas._libs.lib.fast_unique_multiple_list}\n",
      "       13    0.000    0.000    0.000    0.000 {pandas._libs.lib.get_blkno_indexers}\n",
      "      144    0.000    0.000    0.000    0.000 {pandas._libs.lib.infer_datetimelike_array}\n",
      "      150    0.001    0.000    0.001    0.000 {pandas._libs.lib.infer_dtype}\n",
      "       55    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_bool_array}\n",
      "       78    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_bool}\n",
      "       45    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_datetime_array}\n",
      "      123    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_float}\n",
      "      172    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_integer}\n",
      "       86    0.001    0.000    0.001    0.000 {pandas._libs.lib.isnaobj}\n",
      "      539    0.000    0.000    0.000    0.000 {pandas._libs.lib.isscalar}\n",
      "       54    0.000    0.000    0.000    0.000 {pandas._libs.lib.list_to_object_array}\n",
      "       30    0.001    0.000    0.001    0.000 {pandas._libs.lib.map_infer_mask}\n",
      "       60    0.001    0.000    0.001    0.000 {pandas._libs.lib.maybe_convert_objects}\n",
      "       30    0.000    0.000    0.000    0.000 {pandas._libs.lib.to_object_array}\n",
      "      180    0.000    0.000    0.000    0.000 {pandas._libs.lib.values_from_object}\n",
      "       81    0.000    0.000    0.000    0.000 {range}\n",
      "        1    0.000    0.000    0.000    0.000 {setattr}\n",
      "       19    0.000    0.000    0.000    0.000 {sorted}\n",
      "       89    0.000    0.000    0.000    0.000 {sum}\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'sort_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-646084c5f915>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcProfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"match_data_board_changer(series_data_mos, series_data)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cum_time'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'sort_values'"
     ]
    }
   ],
   "source": [
    "cProfile.run(\"match_data_board_changer(series_data_mos, series_data)\").sort_values('cum_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process and appended new matches to full_dataset df once a day\n",
    "col_list = ['first_kills', 'who_kill_who','awp_kills']\n",
    "full_dataset = pd.DataFrame()\n",
    "first = True\n",
    "for date in data.date.unique():\n",
    "    print date\n",
    "    cur_slice = data.loc[data.date <= date,:]\n",
    "    new_df = process_slice(cur_slice, col_list)\n",
    "    if not first:\n",
    "        new_df = new_df.loc[~new_df.match_id.isin(full_dataset.match_id),]\n",
    "    else:\n",
    "        first = False\n",
    "    full_dataset = pd.concat([full_dataset, new_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating X and y functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datay = data.loc[:,['winner_of_match', 'player_team_name', 'match_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_adv = pd.get_dummies(data_adv,columns = ['player_team_name', 'player_team_opponent','map'])\n",
    "data_adv = data_adv.drop(['match_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datay.loc[datay.winner_of_match != datay.player_team_name, 'winner_of_match'] = 0\n",
    "datay.loc[datay.winner_of_match == datay.player_team_name, 'winner_of_match'] = 1\n",
    "datay.winner_of_match = datay.winner_of_match.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "datay = datay.groupby(['match_id', 'player_team_name'])['winner_of_match'].mean()\n",
    "datay = pd.DataFrame(datay)\n",
    "datay = datay.reset_index()\n",
    "datay = datay.drop(['player_team_name','match_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1037,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data_adv = data_adv.drop(['Mirage_win_his','Mirage_loss_his','Train_win_his','Train_loss_his','Cobblestone_win_his'\n",
    "#                      ,'Cobblestone_loss_his','Cache_win_his','Cache_loss_his','Inferno_win_his','Inferno_loss_his'\n",
    "#                      ,'Overpass_win_his','Overpass_loss_his','Nuke_win_his','Nuke_loss_his'], axis = 1)\n",
    "\n",
    "\n",
    "# ,'who_kill_who_Cache_dr_hist'\n",
    "#                       ,'who_kill_who_Cobblestone_dr_hist','who_kill_who_Inferno_dr_hist','who_kill_who_Mirage_dr_hist'\n",
    "#                       ,'who_kill_who_Nuke_dr_hist','who_kill_who_Overpass_dr_hist','who_kill_who_Train_dr_hist'\n",
    "#                       , 'who_kill_who_sum_dr_hist'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_adv = data_adv.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1039,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = datay.values.astype(int)\n",
    "X = data_adv.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def local_cv(model, params):                             #KFOLD WITH GRID SEARCH\n",
    "    param_grid = params\n",
    "    kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "    grid_result = grid.fit(X, y)\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    for params, mean_score, scores in grid_result.grid_scores_:\n",
    "        print(\"%f (%f) with: %r\" % (scores.mean(), scores.std(), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_folds = 10\n",
    "num_instances = len(X) \n",
    "seed = 7\n",
    "scoring = 'roc_auc'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X = data_adv.iloc[:,top_56_important_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.692009 (0.041771)\n",
      "LASSO: 0.605929 (0.047575)\n",
      "Ridge: 0.693587 (0.040757)\n",
      "LDA: 0.683520 (0.041036)\n",
      "NB: 0.673947 (0.044565)\n",
      "KNeighborsClassifier: 0.584792 (0.056266)\n",
      "XGBClassifier: 0.691801 (0.041618)\n",
      "GradientBoostingClassifier: 0.676411 (0.037104)\n",
      "AdaBoostClassifier: 0.692027 (0.045368)\n",
      "RandomForestClassifier: 0.605450 (0.044938)\n",
      "ExtraTreesClassifier: 0.572198 (0.055233)\n",
      "DecisionTreeClassifier: 0.576211 (0.064759)\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression(random_state = seed)))\n",
    "models.append(('LASSO', Lasso())) \n",
    "models.append(('Ridge', Ridge())) \n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('KNeighborsClassifier', KNeighborsClassifier()))#ewights = 'distance' \n",
    "models.append(('XGBClassifier', xgb.XGBClassifier()))\n",
    "models.append(('GradientBoostingClassifier', GradientBoostingClassifier(random_state = seed)))\n",
    "models.append(('AdaBoostClassifier', AdaBoostClassifier(random_state = seed)))\n",
    "models.append(('RandomForestClassifier', RandomForestClassifier(random_state = seed)))\n",
    "models.append(('ExtraTreesClassifier', ExtraTreesClassifier(random_state = seed)))\n",
    "models.append(('DecisionTreeClassifier', DecisionTreeClassifier(random_state = seed)))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(shuffle = True, n_splits=num_folds, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring = scoring)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of feature: 85\n",
      "Feature Ranking: [ 1  1  1  1  4  1 10  1  1  1  1  1  1  1  1  1  1  1  1  9  1  1  1  1  1\n",
      " 11  5  1  1  1  3  1  1  8  1  6  7  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "estimator = LinearDiscriminantAnalysis()\n",
    "rfe = RFECV(estimator,cv = kfold)\n",
    "fit = rfe.fit(X,y)\n",
    "print(\"Num of feature: %d\") % fit.n_features_\n",
    "#print(\"Selected features: %s\") % fit.support_\n",
    "print(\"Feature Ranking: %s\") % fit.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 first_kills_sum_dr_hist\n",
      "1 awp_kills_sum_dr_hist\n",
      "2 ADR_hist\n",
      "3 Train_total_played\n",
      "5 Cache_total_played\n",
      "7 Overpass_total_played\n",
      "8 Mirage_total_played\n",
      "9 Nuke_total_played\n",
      "10 Train_win_perc_map\n",
      "11 Cobblestone_win_perc_map\n",
      "12 Cache_win_perc_map\n",
      "13 Inferno_win_perc_map\n",
      "14 Overpass_win_perc_map\n",
      "15 Mirage_win_perc_map\n",
      "16 Nuke_win_perc_map\n",
      "17 rd_total_his_Ghost\n",
      "18 rd_total_his_OpTic\n",
      "20 rd_total_his_Luminosity\n",
      "21 rd_total_his_CLG\n",
      "22 rd_total_his_NRG\n",
      "23 rd_total_his_Cloud9\n",
      "24 rd_total_his_Immortals\n",
      "27 rd_total_his_Rogue\n",
      "28 rd_total_his_Misfits\n",
      "29 rd_total_his_Splyce\n",
      "31 total_team_rd_Cache\n",
      "32 total_team_rd_Cobblestone\n",
      "34 total_team_rd_Mirage\n",
      "37 total_team_rd_Nuke\n",
      "38 ADR_his_Cache\n",
      "39 ADR_his_Cobblestone\n",
      "40 ADR_his_Inferno\n",
      "41 ADR_his_Mirage\n",
      "42 ADR_his_Nuke\n",
      "43 ADR_his_Overpass\n",
      "44 ADR_his_Train\n",
      "45 first_kills_Cache_dr_hist\n",
      "46 first_kills_Cobblestone_dr_hist\n",
      "47 first_kills_Inferno_dr_hist\n",
      "48 first_kills_Mirage_dr_hist\n",
      "49 first_kills_Nuke_dr_hist\n",
      "50 first_kills_Overpass_dr_hist\n",
      "51 first_kills_Train_dr_hist\n",
      "52 awp_kills_Cache_dr_hist\n",
      "53 awp_kills_Cobblestone_dr_hist\n",
      "54 awp_kills_Inferno_dr_hist\n",
      "55 awp_kills_Mirage_dr_hist\n",
      "56 awp_kills_Nuke_dr_hist\n",
      "57 awp_kills_Overpass_dr_hist\n",
      "58 awp_kills_Train_dr_hist\n",
      "59 matches_played_player\n",
      "60 player_team_name_CLG\n",
      "61 player_team_name_Cloud9\n",
      "62 player_team_name_Ghost\n",
      "63 player_team_name_Immortals\n",
      "64 player_team_name_Liquid\n",
      "65 player_team_name_Luminosity\n",
      "66 player_team_name_Misfits\n",
      "67 player_team_name_NRG\n",
      "68 player_team_name_OpTic\n",
      "69 player_team_name_Renegades\n",
      "70 player_team_name_Rogue\n",
      "71 player_team_name_SK\n",
      "72 player_team_name_Splyce\n",
      "74 player_team_opponent_CLG\n",
      "75 player_team_opponent_Cloud9\n",
      "76 player_team_opponent_Ghost\n",
      "77 player_team_opponent_Immortals\n",
      "78 player_team_opponent_Liquid\n",
      "79 player_team_opponent_Luminosity\n",
      "80 player_team_opponent_Misfits\n",
      "81 player_team_opponent_NRG\n",
      "82 player_team_opponent_OpTic\n",
      "83 player_team_opponent_Renegades\n",
      "84 player_team_opponent_Rogue\n",
      "85 player_team_opponent_SK\n",
      "86 player_team_opponent_Splyce\n",
      "87 player_team_opponent_compLexity\n",
      "88 map_Cache\n",
      "89 map_Cobblestone\n",
      "90 map_Inferno\n",
      "91 map_Mirage\n",
      "92 map_Nuke\n",
      "93 map_Overpass\n",
      "94 map_Train\n"
     ]
    }
   ],
   "source": [
    "top_85_important_features = [] \n",
    "for b in range(0,len(fit.ranking_)):\n",
    "    if fit.ranking_[b] == 1:\n",
    "        top_85_important_features.append(b)\n",
    "        print b,data_adv.columns[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1054-3aae622ce6d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mestimators\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mensemble\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVotingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvoting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'soft'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensemble\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m.69\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\model_selection\\_validation.pyc\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                                               fit_params)\n\u001b[1;32m--> 140\u001b[1;33m                       for train, test in cv_iter)\n\u001b[0m\u001b[0;32m    141\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\model_selection\\_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\ensemble\\voting_classifier.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    163\u001b[0m                 delayed(_parallel_fit_estimator)(clone(clf), X, transformed_y,\n\u001b[0;32m    164\u001b[0m                     sample_weight)\n\u001b[1;32m--> 165\u001b[1;33m                     for _, clf in self.estimators)\n\u001b[0m\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\ensemble\\voting_classifier.pyc\u001b[0m in \u001b[0;36m_parallel_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m   1026\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[1;32m-> 1028\u001b[1;33m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[0;32m   1029\u001b[0m         \u001b[1;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1081\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[0;32m   1082\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1083\u001b[1;33m                                      X_csc, X_csr)\n\u001b[0m\u001b[0;32m   1084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1085\u001b[0m             \u001b[1;31m# track deviance (= loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[1;32m--> 787\u001b[1;33m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m             \u001b[1;31m# update tree leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1027\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1030\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    348\u001b[0m                                            self.min_impurity_split)\n\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for a in range(0, len(models)):\n",
    "    model1 = models[a]\n",
    "    for b in range(a+1, len(models)):\n",
    "        model2 = models[b]\n",
    "        for c in range(b+1, len(models)):\n",
    "            model3 = models[c]\n",
    "            estimators = []\n",
    "            estimators.append(model1)\n",
    "            estimators.append(model2)\n",
    "            estimators.append(model3)\n",
    "            ensemble = VotingClassifier(estimators, voting='soft')\n",
    "            results = model_selection.cross_val_score(ensemble, X, y, cv=kfold, scoring= scoring)\n",
    "            if results.mean() > .69:\n",
    "                print(model1[0], model2[0], model3[0],results.mean(), results.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
