{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy: 0.19.1\n",
      "numpy: 1.12.1\n",
      "matplotlib: 2.0.2\n",
      "pandas: 0.20.3\n",
      "sklearn: 0.19.0\n"
     ]
    }
   ],
   "source": [
    "import cPickle as pkl\n",
    "from cspython.scraper import modifiedSoup\n",
    "from cspython.data_processing import process_scrapped\n",
    "import cPickle as pkl\n",
    "import sys\n",
    "sys.setrecursionlimit(15000)\n",
    "\n",
    "import cspython.analysis as a\n",
    "import scipy\n",
    "print('scipy: {}'.format(scipy.__version__)) # numpy\n",
    "import numpy as np\n",
    "print('numpy: {}'.format(np.__version__))\n",
    "# matplotlib\n",
    "\n",
    "\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "print('matplotlib: {}'.format(matplotlib.__version__)) # pandas\n",
    "import pandas as pd\n",
    "print('pandas: {}'.format(pd.__version__))\n",
    "# scikit-learn\n",
    "#import sklearn\n",
    "#print('sklearn: {}'.format(sklearn.__version__))\n",
    "#import xlrd\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import sklearn\n",
    "print('sklearn: {}'.format(sklearn.__version__))\n",
    "#import xlrd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import Lasso, Ridge  \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.feature_selection import RFE\n",
    "import xgboost as xgb\n",
    "from sklearn import cross_validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import cross_validation #might be model_selection <--- this is the new one\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing \n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import pdb\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import cross_validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../cspython/esl_teams.pkl', 'rb') as f: \n",
    "     d = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with open('../cspython/test.pkl', 'rb') as f: \n",
    "#     d = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "big_data = process_scrapped(d)\n",
    "overview, big_data = big_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_dfs(overview, big_data):\n",
    "    first=True\n",
    "    cols = ['map','round_num','half','match_id','series_id','ending','CT','T','side_winner','winner','team_A','team_B','team_A_score','team_B_score','match_num','team_players','K-D','+/-','ADR','KAST','Rating2.0','nicknames']\n",
    "    dfs = []\n",
    "    for idx, series_data in big_data.iteritems():\n",
    "        series_data_m = merge_matches(series_data)\n",
    "        series_data_m.loc[:,\"date\"] = overview.loc[overview.id == idx, 'date'].values[0]\n",
    "        series_data_mo = merge_overview(series_data_m, series_data)\n",
    "        series_data_mos = merge_scoreboards(series_data_mo, series_data)\n",
    "        series_data_mosm = match_data_board_changer(series_data_mos, series_data)\n",
    "        dfs.append(series_data_mosm)    \n",
    "        new_cols = list(set(series_data_mosm.columns) -set(cols))\n",
    "        cols += new_cols\n",
    "    data = pd.concat(dfs)\n",
    "    data = data.loc[:,cols]\n",
    "    data = data.reset_index()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_matches(series_data):\n",
    "    for d in range(0,len(series_data['matches'])):\n",
    "        if d == 0:\n",
    "            series_data['matches'][d] = series_data['matches'][d].rename(index = str, columns={ series_data['matches'][d].columns[10] : \"team_A\", series_data['matches'][d].columns[11] : \"team_B\" })\n",
    "            series_data_m = series_data['matches'][d]\n",
    "        else:\n",
    "            series_data['matches'][d] = series_data['matches'][d].rename(index = str, columns={ series_data['matches'][d].columns[10] : \"team_A\", series_data['matches'][d].columns[11] : \"team_B\" })\n",
    "            series_data_m = pd.concat([series_data_m, series_data['matches'][d]])\n",
    "    \n",
    "    return series_data_m\n",
    "    #should work for concact the matches together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_overview(series_data_m, series_data):\n",
    "    series_data['match_overview'].loc[:,'team_A_name'] = series_data['match_overview'].columns[4]\n",
    "    series_data['match_overview'].loc[:,'team_B_name'] = series_data['match_overview'].columns[5]\n",
    "    \n",
    "    series_data['match_overview'].loc[(series_data['match_overview']['winner'] == series_data['match_overview'].columns[4]),'loser_of_match'] = series_data['match_overview'].team_B_name\n",
    "    series_data['match_overview'].loc[(series_data['match_overview']['winner'] != series_data['match_overview'].columns[4]),'loser_of_match'] = series_data['match_overview'].team_A_name\n",
    "    series_data['match_overview'] = series_data['match_overview'].rename(index = str, columns ={series_data['match_overview'].columns[3]: \"winner_of_match\",series_data['match_overview'].columns[4]: \"team_A_score\",series_data['match_overview'].columns[5]: \"team_B_score\"})\n",
    "    \n",
    "    \n",
    "    series_data_mo = pd.merge(series_data_m, series_data['match_overview'], on=['match_id', 'map', 'series_id'])\n",
    "    \n",
    "    return series_data_mo\n",
    "#works at merging matches with match_overviewb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_scoreboards(series_data_mo, series_data):    \n",
    "   \n",
    "    for i in range(len(series_data['scoreboards'][0])):\n",
    "        series_data['scoreboards'][0][i]['match_num'] = i+1\n",
    "        #pdb.set_trace()\n",
    "        series_data['scoreboards'][0][i]['player_team_name'] = series_data_mo.loc[(series_data_mo['match_num']== i+1),'team_A_name'].unique()[0]\n",
    "        series_data['scoreboards'][0][i] = series_data['scoreboards'][0][i].rename(index = str, columns={ series_data['scoreboards'][0][i].columns[0] : \"team_players\" })\n",
    "        \n",
    "        series_data['scoreboards'][1][i]['match_num'] = i+1\n",
    "        series_data['scoreboards'][1][i]['player_team_name'] = series_data_mo.loc[(series_data_mo['match_num']== i+1),'team_B_name'].unique()[0]\n",
    "        series_data['scoreboards'][1][i] = series_data['scoreboards'][1][i].rename(index = str, columns={ series_data['scoreboards'][1][i].columns[0] : \"team_players\"})\n",
    "        \n",
    "        new_df = pd.concat([series_data['scoreboards'][0][i], series_data['scoreboards'][1][i]])\n",
    "        \n",
    "        if i == 0:\n",
    "            con_df = new_df\n",
    "        else:\n",
    "            con_df = pd.concat([con_df, new_df])\n",
    "   \n",
    "    series_data_mos = pd.merge(series_data_mo, con_df, how='outer', on='match_num')\n",
    "    series_data_mos['nicknames'] = series_data_mos['team_players'].str.split(pat = \"'\",expand = True)[1]\n",
    "    return series_data_mos\n",
    "\n",
    "       \n",
    "        \n",
    "#works at adding match_num to scoreboards\n",
    "        \n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def match_data_board_changer(series_data_mos,series_data):\n",
    "    \n",
    "    board_name = ['first_kills','who_kill_who', 'awp_kills']\n",
    "\n",
    "    for idx, a in enumerate(series_data['match_data']):\n",
    "        new_df = pd.DataFrame()\n",
    "        for idx1, c in enumerate(board_name):    \n",
    "            new_board_c = pd.DataFrame()\n",
    "            new_board_r= pd.DataFrame()\n",
    "            names_c = a[c].set_index('Unnamed: 0').columns\n",
    "            for b in names_c:\n",
    "                new_board_c[b+'_'+c] = a[c].set_index('Unnamed: 0')[b].str.split(pat = ':', expand = True)[0]\n",
    "               \n",
    "            names_r = a[c].set_index('Unnamed: 0').T.columns\n",
    "            for b in names_r:\n",
    "                new_board_r[b+'_'+c] = a[c].set_index('Unnamed: 0').T[b].str.split(pat = ':', expand = True)[1]\n",
    "            new_board_c['nicknames'] = new_board_c.index\n",
    "            new_board_r['nicknames'] = new_board_r.index\n",
    "            \n",
    "            board_df = new_board_c.append(new_board_r)\n",
    "            \n",
    "            if idx1 == 0:\n",
    "                new_df = board_df\n",
    "            else:\n",
    "                new_df = pd.merge(new_df, board_df, on = 'nicknames')\n",
    "        if idx == 0:\n",
    "            new_df['match_num'] = 1+idx\n",
    "            con_df = new_df\n",
    "        else:\n",
    "            new_df['match_num'] = 1+idx\n",
    "            try:\n",
    "                con_df = con_df.append(new_df, ignore_index=True)\n",
    "            except:\n",
    "                print con_df.columns\n",
    "                print new_df.columns\n",
    "    con_df = con_df.loc[:, ~con_df.columns.duplicated()]\n",
    "    #pdb.set_trace()\n",
    "  \n",
    "    series_data_mosm = pd.merge(series_data_mos, con_df, on=['nicknames','match_num'])\n",
    "    return series_data_mosm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data = combine_dfs(overview, big_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data.to_pickle(\"data_converged.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"data_converged.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_opponent_team_col(data):\n",
    "    data.loc[:,'player_team_opponent'] = np.nan\n",
    "    data.loc[(data['team_A_name'] != data['player_team_name']),'player_team_opponent'] = data.loc[:,'team_A_name']\n",
    "    data.loc[(data['team_B_name'] != data['player_team_name']),'player_team_opponent'] = data.loc[:,'team_B_name']\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_fwa_dr_columns(data, col_list):  # first k , awp, who, divided by rounds \n",
    "    columns = pd.Series(data.columns)\n",
    "    for a in col_list:\n",
    "        col = columns[columns.str.contains(a)]\n",
    "        data[a+'_sum_dr'] = data[col].convert_objects(convert_numeric = True).sum(axis = 1) / (data['team_A_score'] + data['team_B_score'])*100\n",
    "    data.loc[:, data.columns != 'date'] = data.loc[:, data.columns != 'date'].apply(pd.to_numeric, errors='ignore')\n",
    "    return data\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_player_columns(data):\n",
    "    names = data.nicknames.unique()\n",
    "    for a in names:\n",
    "        data.loc[:,a] = 0\n",
    "        data.loc[data.loc[:,'nicknames'] == a, a] = 5   # its 5 so that when you group by team it becomes 1 \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_nummeric_and_group_as_match(data):\n",
    "    r = data.loc[:, data.columns != 'date'].apply(pd.to_numeric, errors='ignore')\n",
    "    r['date'] = data.date\n",
    "    data = r\n",
    "    data = data.fillna(0)\n",
    "    data_match = data.groupby(['match_id', 'player_team_name', 'date', 'team_A_name', 'team_B_name', 'series_id', 'map', 'winner_of_match', 'loser_of_match','player_team_opponent']).mean()\n",
    "    data_match = pd.DataFrame(data_match)\n",
    "    data_match = data_match.reset_index()\n",
    "    return data_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['first_kills', 'who_kill_who','awp_kills']\n",
    "data = create_opponent_team_col(data)\n",
    "data = create_fwa_dr_columns(data, col_list)\n",
    "data = create_player_columns(data)\n",
    "data = apply_nummeric_and_group_as_match(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data.to_pickle(\"data_converged_historic.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"data_converged_historic.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_historic_data(data):\n",
    "    col_list = ['first_kills', 'who_kill_who','awp_kills']\n",
    "    data = create_fwadr_his(data, col_list)\n",
    "    data = create_matches_count(data)\n",
    "    data = create_avdamage_his(data)\n",
    "    data = create_avdamage_map_his(data)\n",
    "    data = create_faw_map_his(data, col_list)\n",
    "    return data\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_matches_count(data): # how many matches a team has played\n",
    "    teams = list(data.player_team_name.unique())\n",
    "    new_group = pd.DataFrame()\n",
    "    for a in teams:   \n",
    "        data_team = data.loc[data.loc[:,'player_team_name'] == a, ].sort_values(by='date',ascending=True)\n",
    "        grouping = data_team.groupby(['player_team_name','date','match_id'])['ADR'].count()\n",
    "        grouping = pd.DataFrame(grouping)\n",
    "        grouping = grouping.reset_index()\n",
    "        grouping.loc[:,'ADR'] = grouping.loc[:,'ADR'].expanding(min_periods=1, freq=None, center=False, axis=0).sum()\n",
    "        grouping = grouping.rename(index=str, columns={'ADR': 'matches_played_team'})\n",
    "        new_group = pd.concat([new_group, grouping])\n",
    "    data = pd.merge(data, new_group, on = ['player_team_name','match_id','date'])\n",
    "\n",
    "    return data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_avdamage_his(data):  # column with historic average damage of individual !!!\n",
    "    teams = list(data.player_team_name.unique())\n",
    "    new_group = pd.DataFrame()\n",
    "    for a in teams:   \n",
    "        data_team = data.loc[data.loc[:,'player_team_name'] == a, ].sort_values(by='date',ascending=True)\n",
    "        grouping = data_team.groupby(['player_team_name','date','match_id'])['ADR'].max()\n",
    "        grouping = pd.DataFrame(grouping)\n",
    "        grouping = grouping.reset_index()\n",
    "        grouping.loc[:,'ADR'] = grouping.loc[:,'ADR'].expanding(min_periods=1, freq=None, center=False, axis=0).mean()\n",
    "        grouping = grouping.rename(index=str, columns={'ADR': 'ADR_hist'})\n",
    "        new_group = pd.concat([new_group, grouping])\n",
    "    data = pd.merge(data, new_group, on = ['player_team_name','match_id','date'])\n",
    "\n",
    "    return data\n",
    "   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_avdamage_map_his(data):# historic average damage of individual for each map !!!\n",
    "    teams = list(data.player_team_name.unique())\n",
    "    maps = list(data.map.unique())\n",
    "    new_group = pd.DataFrame()\n",
    "    for a in maps:\n",
    "        for b in teams:   \n",
    "            data_team = data.loc[(data.loc[:,'player_team_name'] == b) & (data.loc[:,'map'] == a), ].sort_values(by='date',ascending=True)\n",
    "            grouping = data_team.groupby(['player_team_name','match_id'])['ADR'].max()\n",
    "            grouping = pd.DataFrame(grouping)\n",
    "            grouping = grouping.reset_index()\n",
    "            grouping.loc[:,'ADR'] = grouping.loc[:,'ADR'].expanding(min_periods=1, freq=None, center=False, axis=0).mean()\n",
    "            grouping = grouping.rename(index=str, columns={'ADR': 'ADR_hist_on_map'})\n",
    "            new_group = pd.concat([new_group, grouping])\n",
    "    \n",
    "    data = pd.merge(data, new_group, on = ['match_id','player_team_name'])\n",
    "\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fwadr_his(data, col_list):\n",
    "    teams = list(data.player_team_name.unique())\n",
    "    for b in col_list:\n",
    "        new_group = pd.DataFrame()\n",
    "        for a in teams:   \n",
    "            data_team = data.loc[data.loc[:,'player_team_name'] == a, ].sort_values(by='date',ascending=True)\n",
    "            grouping = data_team.groupby(['player_team_name','date','match_id'])[b+'_sum_dr'].max()\n",
    "            grouping = pd.DataFrame(grouping)\n",
    "            grouping = grouping.reset_index()\n",
    "            grouping.loc[:,b +'_sum_dr'] = grouping.loc[:,b +'_sum_dr'].expanding(min_periods=1, freq=None, center=False, axis=0).mean()\n",
    "            grouping = grouping.rename(index=str, columns={b +'_sum_dr': b + '_sum_dr_hist'})\n",
    "            new_group = pd.concat([new_group, grouping])\n",
    "        data = pd.merge(data, new_group, on = ['player_team_name','match_id','date'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_faw_map_his(data, col_list):\n",
    "    teams = list(data.player_team_name.unique())\n",
    "    maps = list(data.map.unique())\n",
    "    for b in col_list:\n",
    "        new_group = pd.DataFrame()\n",
    "        for i in maps:\n",
    "            for a in teams:   \n",
    "                data_team = data.loc[(data.loc[:,'player_team_name'] == a) & (data.loc[:,'map'] == i), ].sort_values(by='date',ascending=True)\n",
    "                grouping = data_team.groupby(['player_team_name','match_id'])[b+'_sum_dr'].max()\n",
    "                grouping = pd.DataFrame(grouping)\n",
    "                grouping = grouping.reset_index()\n",
    "                grouping.loc[:,b +'_sum_dr'] = grouping.loc[:,b +'_sum_dr'].expanding(min_periods=1, freq=None, center=False, axis=0).mean()\n",
    "                grouping = grouping.rename(index=str, columns={b +'_sum_dr': b + '_sum_dr_hist_on_map'})\n",
    "                new_group = pd.concat([new_group, grouping])\n",
    "                \n",
    "        data = pd.merge(data, new_group, on = ['match_id','player_team_name'])\n",
    "    return data   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_historic_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.loc[(data.loc[:,'player_team_name'] == 'Cloud9') & (data.loc[:,'map'] == 'Inferno'),].sort_values(by='date',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  FUNCTIONS BELOW HERE NEED TO BE WORKED ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_map_win_loss_his(data):  # team total win and loses on map with total times played on map !4!\n",
    "    maps = data.map.unique()\n",
    "    match_id = data.match_id.unique()\n",
    "    for a in maps:\n",
    "        data[a + \"_win_his\"] = 0\n",
    "        data[a + \"_loss_his\"] = 0\n",
    "        data[a + \"_total_played\"] = 0\n",
    "    for a in match_id:\n",
    "        map_for_match = data.loc[(data['match_id'] == a) ,'map'].unique()\n",
    "        winner_of_map = data.loc[(data['match_id'] == a), 'winner_of_match'].unique()\n",
    "        loser_of_map = data.loc[(data['match_id'] == a), 'loser_of_match'].unique()\n",
    "        data.loc[(data['player_team_name'] == winner_of_map[0]), [map_for_match[0] + \"_win_his\", map_for_match[0] +'_total_played']] += 1\n",
    "        data.loc[(data['player_team_name'] == loser_of_map[0]), [map_for_match[0] + \"_loss_his\", map_for_match[0] +'_total_played']] += 1 \n",
    "       \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_map_win_his_per(data): #percentage team total win and loses on map !5!\n",
    "    teams = data.player_team_name.unique()\n",
    "    maps = data.map.unique()\n",
    "    for a in maps:\n",
    "        data[a + '_win_perc_map'] = 0\n",
    "        for b in teams:\n",
    "            pg = (data.player_team_name == b) \n",
    "            data.loc[pg,a + '_win_perc_map'] = data.loc[pg, a + \"_win_his\"].unique()[0] / float((data.loc[pg, a + \"_win_his\"].unique()[0] + data.loc[pg, a + \"_loss_his\"].unique()[0])) * 100 \n",
    "    data = data.fillna(0)        \n",
    "    return data    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_rounds_won_vs_team_his(data): # team rounds won vs another team    !6!\n",
    "    grouping = data.groupby(['match_id','map','team_A_name','team_B_name', 'team_A_score', 'team_B_score'])['round_num'].count()\n",
    "    grouping = pd.DataFrame(grouping)\n",
    "    grouping = grouping.add_suffix('_Count').reset_index()\n",
    "    grouping = grouping.groupby(['team_A_name', 'team_B_name']).sum()\n",
    "    grouping = pd.DataFrame(grouping)\n",
    "    grouping = grouping.add_suffix('_Count').reset_index()\n",
    "    forward = grouping.team_A_name+grouping.team_B_name\n",
    "    reverse = grouping.team_B_name+grouping.team_A_name\n",
    "    for idx, val in enumerate(forward):\n",
    "        for idx2, val2 in enumerate(reverse):\n",
    "            if val == val2 and idx < idx2:\n",
    "                grouping.loc[idx,'team_A_score_Count'] += grouping.loc[idx2,'team_B_score_Count']\n",
    "                grouping.loc[idx,'team_B_score_Count'] += grouping.loc[idx2,'team_A_score_Count']\n",
    "                grouping.loc[idx2,'team_B_score_Count'] = grouping.loc[idx,'team_A_score_Count']\n",
    "                grouping.loc[idx2,'team_A_score_Count'] = grouping.loc[idx,'team_B_score_Count']\n",
    "            elif val == val2 and idx > idx2:\n",
    "                grouping.loc[idx2,'team_B_score_Count'] = grouping.loc[idx,'team_A_score_Count']\n",
    "                grouping.loc[idx2,'team_A_score_Count'] = grouping.loc[idx,'team_B_score_Count']\n",
    "    \n",
    "    grouping = grouping.drop('round_num_Count_Count', axis = 1)\n",
    "    col1 = list(grouping.team_A_name.unique())\n",
    "    col2  = list(grouping.team_B_name.unique())\n",
    "    col = col1 + col2\n",
    "    col = list(set(col))\n",
    "    data = pd.merge(data,grouping, on=['team_A_name', 'team_B_name']) \n",
    "    for a in col:\n",
    "        data['rd_total_his_'+ a] = 0\n",
    "        data.loc[(data.player_team_name != a) & (data.team_A_name == a) , 'rd_total_his_'+ a]=data.team_B_score_Count\n",
    "        data.loc[(data.player_team_name != a) & (data.team_B_name == a) , 'rd_total_his_'+ a]=data.team_A_score_Count\n",
    "        bgrouping = data.groupby(['player_team_name'])['rd_total_his_'+ a].max()\n",
    "        bgrouping = pd.DataFrame(bgrouping)\n",
    "        bgrouping = bgrouping.reset_index()\n",
    "        data = data.drop('rd_total_his_'+ a, axis = 1)\n",
    "        data = pd.merge(data, bgrouping, on = 'player_team_name')\n",
    "       \n",
    "    return data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_total_team_rd_map_his(data):\n",
    "    grouping = data.groupby(['map','team_A_name', 'team_A_score'])['round_num'].count()\n",
    "    grouping = pd.DataFrame(grouping)\n",
    "    grouping = grouping.add_suffix('_Count').reset_index()\n",
    "    grouping = grouping.groupby(['map','team_A_name'])[ 'team_A_score'].sum()\n",
    "    grouping = pd.DataFrame(grouping)\n",
    "    grouping = grouping.add_suffix('_Count').reset_index()\n",
    "    fgrouping = data.groupby(['player_team_name','map','team_B_name', 'team_B_score'])['round_num'].count()\n",
    "    fgrouping = pd.DataFrame(fgrouping)\n",
    "    fgrouping = fgrouping.add_suffix('_Count').reset_index()\n",
    "    fgrouping = fgrouping.groupby(['map','team_B_name'])[ 'team_B_score'].sum()\n",
    "    fgrouping = pd.DataFrame(fgrouping)\n",
    "    fgrouping = fgrouping.add_suffix('_Count').reset_index()\n",
    "    fgrouping = fgrouping.rename(index=str, columns={\"team_B_name\": \"team_A_name\", 'team_B_score_Count': 'team_A_score_Count'})\n",
    "    merged = pd.concat([grouping, fgrouping], axis = 0)\n",
    "    merged.groupby(['map', 'team_A_name'])['team_A_score_Count'].sum()\n",
    "    merged = pd.DataFrame(merged)\n",
    "    merged = merged.reset_index(drop = True)\n",
    "    merged = merged.rename(index=str, columns={\"team_A_name\": \"player_team_name\", \"team_A_score_Count\": 'total_team_rd_map'})\n",
    "    merged = merged.groupby(['player_team_name', 'map']).sum()\n",
    "    merged = pd.DataFrame(merged)\n",
    "    merged = merged.reset_index()\n",
    "    for a in list(merged.map.unique()):\n",
    "        merged.loc[:,'total_team_rd_'+ a] = 0\n",
    "        merged.loc[(merged.loc[:, 'map'] == a), 'total_team_rd_'+ a] = merged.loc[:,'total_team_rd_map']\n",
    "        ok_map = merged.groupby(['player_team_name'])['total_team_rd_'+ a].max()\n",
    "        ok_map = pd.DataFrame(ok_map)\n",
    "        ok_map = ok_map.reset_index()\n",
    "        data = pd.merge(data, ok_map, on = 'player_team_name')\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#FUNCTIONS ABOVE HERE NEED TO BE WORKED ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data.to_pickle(\"data_converged_changed.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_list = ['first_kills', 'who_kill_who','awp_kills']\n",
    "data = create_fwa_dr_columns(data, col_list)\n",
    "data = create_fwadr_his(data,col_list)\n",
    "data = create_avdamage_his(data)\n",
    "data = create_map_win_loss_his(data)\n",
    "data = create_map_win_his_per(data)\n",
    "data = create_rounds_won_vs_team_his(data)\n",
    "data = create_total_team_rd_map_his(data)\n",
    "data = create_avdamage_map_his(data)\n",
    "data = create_faw_map_his(data, col_list)\n",
    "data = create_matches_count(data)\n",
    "data = create_opponent_team_col(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"data_converged_changed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_adv = data.loc[:, 'first_kills_sum_dr_hist':'player_team_opponent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_adv['date'] = data['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_adv['match_id'] = data['match_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_adv['player_team_name'] = data['player_team_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_adv['map'] = data['map']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_adv['winner_of_match']= data['winner_of_match']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_adv = data_adv.drop(['team_A_score_Count','team_B_score_Count'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_adv = data_adv.groupby(['match_id', 'player_team_name', 'player_team_opponent','map', 'winner_of_match', 'date']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_adv = pd.DataFrame(data_adv)\n",
    "data_adv = data_adv.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_adv = data_adv.sort_values('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_adv = data_adv.drop(['Mirage_win_his','Mirage_loss_his','Train_win_his','Train_loss_his','Cobblestone_win_his'\n",
    "                      ,'Cobblestone_loss_his','Cache_win_his','Cache_loss_his','Inferno_win_his','Inferno_loss_his'\n",
    "                       ,'Overpass_win_his','Overpass_loss_his','Nuke_win_his','Nuke_loss_his','who_kill_who_Cache_dr_hist'\n",
    "                       ,'who_kill_who_Cobblestone_dr_hist','who_kill_who_Inferno_dr_hist','who_kill_who_Mirage_dr_hist'\n",
    "                       ,'who_kill_who_Nuke_dr_hist','who_kill_who_Overpass_dr_hist','who_kill_who_Train_dr_hist'\n",
    "                       , 'who_kill_who_sum_dr_hist'], axis = 1)#'player_team_name_CLG','player_team_name_Cloud9', 'player_team_name_Ghost'\n",
    "#                       ,'player_team_name_Immortals', 'player_team_name_Liquid','player_team_name_Luminosity'\n",
    "#                       , 'player_team_name_Misfits','player_team_name_NRG', 'player_team_name_OpTic','player_team_name_Renegades'\n",
    "#                       , 'player_team_name_Rogue','player_team_name_SK', 'player_team_name_Splyce','player_team_name_compLexity','map_Cache'\n",
    "#                       ,'map_Cobblestone','map_Inferno','map_Mirage','map_Nuke','map_Overpass','map_Train'\n",
    "#                       ,'player_team_opponent_CLG','player_team_opponent_Cloud9','player_team_opponent_Ghost'\n",
    "#                       ,'player_team_opponent_Immortals','player_team_opponent_Liquid','player_team_opponent_Luminosity'\n",
    "#                       ,'player_team_opponent_Misfits','player_team_opponent_NRG','player_team_opponent_OpTic'\n",
    "#                       ,'player_team_opponent_Renegades','player_team_opponent_Rogue','player_team_opponent_SK'\n",
    "#                       ,'player_team_opponent_Splyce','player_team_opponent_compLexity'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_adv_even = data_adv.iloc[::2]  # even\n",
    "data_adv_odd = data_adv.iloc[1::2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_adv_merged = pd.merge(data_adv_even, data_adv_odd, on =['match_id', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1208, 66)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_adv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_adv_merged.loc[:,data_adv_merged.columns != 'date'] = data_adv_merged.loc[:,data_adv_merged.columns != 'date'].apply(pd.to_numeric, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datay = data_adv_merged.loc[:,['winner_of_match_x', 'player_team_name_x', 'match_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_adv_merged = pd.get_dummies(data_adv_merged,columns = ['map_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(544, 136)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_adv_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datay.loc[datay.winner_of_match_x != datay.player_team_name_x, 'winner_of_match_x'] = 0\n",
    "datay.loc[datay.winner_of_match_x == datay.player_team_name_x, 'winner_of_match_x'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datay.winner_of_match_x = datay.winner_of_match_x.apply(pd.to_numeric, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datay = datay.drop(['player_team_name_x','match_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_adv_merged = data_adv_merged.drop(['match_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player_team_name_x\n",
      "player_team_opponent_x\n",
      "winner_of_match_x\n",
      "date\n",
      "first_kills_sum_dr_hist_x\n",
      "awp_kills_sum_dr_hist_x\n",
      "ADR_hist_x\n",
      "Train_total_played_x\n",
      "Cobblestone_total_played_x\n",
      "Mirage_total_played_x\n",
      "Cache_total_played_x\n",
      "Inferno_total_played_x\n",
      "Overpass_total_played_x\n",
      "Nuke_total_played_x\n",
      "Train_win_perc_map_x\n",
      "Cobblestone_win_perc_map_x\n",
      "Mirage_win_perc_map_x\n",
      "Cache_win_perc_map_x\n",
      "Inferno_win_perc_map_x\n",
      "Overpass_win_perc_map_x\n",
      "Nuke_win_perc_map_x\n",
      "rd_total_his_Ghost_x\n",
      "rd_total_his_OpTic_x\n",
      "rd_total_his_Liquid_x\n",
      "rd_total_his_Luminosity_x\n",
      "rd_total_his_CLG_x\n",
      "rd_total_his_NRG_x\n",
      "rd_total_his_Cloud9_x\n",
      "rd_total_his_Immortals_x\n",
      "rd_total_his_SK_x\n",
      "rd_total_his_compLexity_x\n",
      "rd_total_his_Rogue_x\n",
      "rd_total_his_Misfits_x\n",
      "rd_total_his_Splyce_x\n",
      "rd_total_his_Renegades_x\n",
      "total_team_rd_Cache_x\n",
      "total_team_rd_Cobblestone_x\n",
      "total_team_rd_Inferno_x\n",
      "total_team_rd_Mirage_x\n",
      "total_team_rd_Overpass_x\n",
      "total_team_rd_Train_x\n",
      "total_team_rd_Nuke_x\n",
      "ADR_his_Cache_x\n",
      "ADR_his_Cobblestone_x\n",
      "ADR_his_Inferno_x\n",
      "ADR_his_Mirage_x\n",
      "ADR_his_Nuke_x\n",
      "ADR_his_Overpass_x\n",
      "ADR_his_Train_x\n",
      "first_kills_Cache_dr_hist_x\n",
      "first_kills_Cobblestone_dr_hist_x\n",
      "first_kills_Inferno_dr_hist_x\n",
      "first_kills_Mirage_dr_hist_x\n",
      "first_kills_Nuke_dr_hist_x\n",
      "first_kills_Overpass_dr_hist_x\n",
      "first_kills_Train_dr_hist_x\n",
      "awp_kills_Cache_dr_hist_x\n",
      "awp_kills_Cobblestone_dr_hist_x\n",
      "awp_kills_Inferno_dr_hist_x\n",
      "awp_kills_Mirage_dr_hist_x\n",
      "awp_kills_Nuke_dr_hist_x\n",
      "awp_kills_Overpass_dr_hist_x\n",
      "awp_kills_Train_dr_hist_x\n",
      "matches_played_player_x\n",
      "player_team_name_y\n",
      "player_team_opponent_y\n",
      "map_y\n",
      "winner_of_match_y\n",
      "first_kills_sum_dr_hist_y\n",
      "awp_kills_sum_dr_hist_y\n",
      "ADR_hist_y\n",
      "Train_total_played_y\n",
      "Cobblestone_total_played_y\n",
      "Mirage_total_played_y\n",
      "Cache_total_played_y\n",
      "Inferno_total_played_y\n",
      "Overpass_total_played_y\n",
      "Nuke_total_played_y\n",
      "Train_win_perc_map_y\n",
      "Cobblestone_win_perc_map_y\n",
      "Mirage_win_perc_map_y\n",
      "Cache_win_perc_map_y\n",
      "Inferno_win_perc_map_y\n",
      "Overpass_win_perc_map_y\n",
      "Nuke_win_perc_map_y\n",
      "rd_total_his_Ghost_y\n",
      "rd_total_his_OpTic_y\n",
      "rd_total_his_Liquid_y\n",
      "rd_total_his_Luminosity_y\n",
      "rd_total_his_CLG_y\n",
      "rd_total_his_NRG_y\n",
      "rd_total_his_Cloud9_y\n",
      "rd_total_his_Immortals_y\n",
      "rd_total_his_SK_y\n",
      "rd_total_his_compLexity_y\n",
      "rd_total_his_Rogue_y\n",
      "rd_total_his_Misfits_y\n",
      "rd_total_his_Splyce_y\n",
      "rd_total_his_Renegades_y\n",
      "total_team_rd_Cache_y\n",
      "total_team_rd_Cobblestone_y\n",
      "total_team_rd_Inferno_y\n",
      "total_team_rd_Mirage_y\n",
      "total_team_rd_Overpass_y\n",
      "total_team_rd_Train_y\n",
      "total_team_rd_Nuke_y\n",
      "ADR_his_Cache_y\n",
      "ADR_his_Cobblestone_y\n",
      "ADR_his_Inferno_y\n",
      "ADR_his_Mirage_y\n",
      "ADR_his_Nuke_y\n",
      "ADR_his_Overpass_y\n",
      "ADR_his_Train_y\n",
      "first_kills_Cache_dr_hist_y\n",
      "first_kills_Cobblestone_dr_hist_y\n",
      "first_kills_Inferno_dr_hist_y\n",
      "first_kills_Mirage_dr_hist_y\n",
      "first_kills_Nuke_dr_hist_y\n",
      "first_kills_Overpass_dr_hist_y\n",
      "first_kills_Train_dr_hist_y\n",
      "awp_kills_Cache_dr_hist_y\n",
      "awp_kills_Cobblestone_dr_hist_y\n",
      "awp_kills_Inferno_dr_hist_y\n",
      "awp_kills_Mirage_dr_hist_y\n",
      "awp_kills_Nuke_dr_hist_y\n",
      "awp_kills_Overpass_dr_hist_y\n",
      "awp_kills_Train_dr_hist_y\n",
      "matches_played_player_y\n",
      "map_x_Cache\n",
      "map_x_Cobblestone\n",
      "map_x_Inferno\n",
      "map_x_Mirage\n",
      "map_x_Nuke\n",
      "map_x_Overpass\n",
      "map_x_Train\n"
     ]
    }
   ],
   "source": [
    "for a in data_adv_merged:\n",
    "    print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_adv_merged = data_adv_merged.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data_adv_temp = data_adv.loc[:,[,'Train_win_perc_map','Cobblestone_win_perc_map','Mirage_win_perc_map'\n",
    "#                                ,'Cache_win_perc_map','Inferno_win_perc_map','Overpass_win_perc_map','Nuke_win_perc_map']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data_adv_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.select_dtypes(include = ['int64', 'float64', 'uint8', 'bool','datetime64[ns]']).iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = datay.values.astype(int)\n",
    "X = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def local_cv(model, params):                             #KFOLD WITH GRID SEARCH\n",
    "    param_grid = params\n",
    "    kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "    grid_result = grid.fit(X, y)\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    for params, mean_score, scores in grid_result.grid_scores_:\n",
    "        print(\"%f (%f) with: %r\" % (scores.mean(), scores.std(), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_folds = 3\n",
    "num_instances = len(X) \n",
    "seed = 7\n",
    "scoring = 'accuracy'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X = data_adv.iloc[:,top_33_important_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.598039 (0.019299)\n",
      "LDA: 0.588235 (0.021646)\n",
      "NB: 0.666667 (0.029615)\n",
      "KNeighborsClassifier: 0.578431 (0.035178)\n",
      "XGBClassifier: 0.629902 (0.039974)\n",
      "GradientBoostingClassifier: 0.620098 (0.009171)\n",
      "AdaBoostClassifier: 0.598039 (0.012498)\n",
      "RandomForestClassifier: 0.575980 (0.024263)\n",
      "ExtraTreesClassifier: 0.605392 (0.063062)\n",
      "DecisionTreeClassifier: 0.580882 (0.036519)\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression(random_state = seed)))\n",
    "#models.append(('LASSO', Lasso())) \n",
    "#models.append(('Ridge', Ridge())) \n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('KNeighborsClassifier', KNeighborsClassifier()))#ewights = 'distance' \n",
    "models.append(('XGBClassifier', xgb.XGBClassifier()))\n",
    "models.append(('GradientBoostingClassifier', GradientBoostingClassifier(random_state = seed)))\n",
    "models.append(('AdaBoostClassifier', AdaBoostClassifier(random_state = seed)))\n",
    "models.append(('RandomForestClassifier', RandomForestClassifier(random_state = seed)))\n",
    "models.append(('ExtraTreesClassifier', ExtraTreesClassifier(random_state = seed)))\n",
    "models.append(('DecisionTreeClassifier', DecisionTreeClassifier(random_state = seed)))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = model_selection.TimeSeriesSplit()\n",
    "    cv_results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring = scoring)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of feature: 33\n",
      "Feature Ranking: [ 1  1  1  1  1  1 14  1  7  8 11 18  4  1  2  1  1 12  1  1  1 17  1 10  5\n",
      "  6  1  1  1 15  1 13  3 19  1  1  1  1 20  1  1  1  1  1  1  1  1  1  9  1\n",
      "  1 16]\n"
     ]
    }
   ],
   "source": [
    "estimator = xgb.XGBClassifier()\n",
    "rfe = RFECV(estimator,cv = kfold)\n",
    "fit = rfe.fit(X,y)\n",
    "print(\"Num of feature: %d\") % fit.n_features_\n",
    "#print(\"Selected features: %s\") % fit.support_\n",
    "print(\"Feature Ranking: %s\") % fit.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 first_kills_sum_dr_hist\n",
      "1 who_kill_who_sum_dr_hist\n",
      "2 awp_kills_sum_dr_hist\n",
      "3 ADR_hist\n",
      "4 Train_win_his\n",
      "5 Train_loss_his\n",
      "7 Cobblestone_win_his\n",
      "13 Cache_win_his\n",
      "15 Cache_total_played\n",
      "16 Inferno_win_his\n",
      "18 Inferno_total_played\n",
      "19 Overpass_win_his\n",
      "20 Overpass_loss_his\n",
      "22 Nuke_win_his\n",
      "26 Cobblestone_win_perc_map\n",
      "27 Mirage_win_perc_map\n",
      "28 Cache_win_perc_map\n",
      "30 Overpass_win_perc_map\n",
      "34 rd_total_his_Liquid\n",
      "35 rd_total_his_Luminosity\n",
      "36 rd_total_his_CLG\n",
      "37 rd_total_his_NRG\n",
      "39 rd_total_his_Immortals\n",
      "40 rd_total_his_SK\n",
      "41 rd_total_his_compLexity\n",
      "42 rd_total_his_Rogue\n",
      "43 rd_total_his_Misfits\n",
      "44 rd_total_his_Splyce\n",
      "45 rd_total_his_Renegades\n",
      "46 total_team_rd_Cache\n",
      "47 total_team_rd_Cobblestone\n",
      "49 total_team_rd_Mirage\n",
      "50 total_team_rd_Overpass\n"
     ]
    }
   ],
   "source": [
    "top_33_important_features = [] \n",
    "for b in range(0,len(fit.ranking_)):\n",
    "    if fit.ranking_[b] == 1:\n",
    "        top_33_important_features.append(b)\n",
    "        print b,data_adv.columns[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1054-3aae622ce6d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mestimators\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mensemble\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVotingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvoting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'soft'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensemble\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m.69\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\model_selection\\_validation.pyc\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                                               fit_params)\n\u001b[1;32m--> 140\u001b[1;33m                       for train, test in cv_iter)\n\u001b[0m\u001b[0;32m    141\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\model_selection\\_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\ensemble\\voting_classifier.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    163\u001b[0m                 delayed(_parallel_fit_estimator)(clone(clf), X, transformed_y,\n\u001b[0;32m    164\u001b[0m                     sample_weight)\n\u001b[1;32m--> 165\u001b[1;33m                     for _, clf in self.estimators)\n\u001b[0m\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\ensemble\\voting_classifier.pyc\u001b[0m in \u001b[0;36m_parallel_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m   1026\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[1;32m-> 1028\u001b[1;33m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[0;32m   1029\u001b[0m         \u001b[1;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1081\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[0;32m   1082\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1083\u001b[1;33m                                      X_csc, X_csr)\n\u001b[0m\u001b[0;32m   1084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1085\u001b[0m             \u001b[1;31m# track deviance (= loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[1;32m--> 787\u001b[1;33m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m             \u001b[1;31m# update tree leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1027\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1030\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    348\u001b[0m                                            self.min_impurity_split)\n\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for a in range(0, len(models)):\n",
    "    model1 = models[a]\n",
    "    for b in range(a+1, len(models)):\n",
    "        model2 = models[b]\n",
    "        for c in range(b+1, len(models)):\n",
    "            model3 = models[c]\n",
    "            estimators = []\n",
    "            estimators.append(model1)\n",
    "            estimators.append(model2)\n",
    "            estimators.append(model3)\n",
    "            ensemble = VotingClassifier(estimators, voting='soft')\n",
    "            results = model_selection.cross_val_score(ensemble, X, y, cv=kfold, scoring= scoring)\n",
    "            if results.mean() > .69:\n",
    "                print(model1[0], model2[0], model3[0],results.mean(), results.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
