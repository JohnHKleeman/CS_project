{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy: 0.19.0\n",
      "numpy: 1.11.3\n",
      "matplotlib: 2.1.0\n",
      "pandas: 0.22.0\n",
      "sklearn: 0.18.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\j_coo\\Anaconda2new\\envs\\csgoproject\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import cPickle as pkl\n",
    "from cspython.scraper import modifiedSoup\n",
    "from cspython.data_processing import process_scrapped\n",
    "import cPickle as pkl\n",
    "import sys\n",
    "sys.setrecursionlimit(15000)\n",
    "\n",
    "import cspython.analysis as a\n",
    "import scipy\n",
    "print('scipy: {}'.format(scipy.__version__)) # numpy\n",
    "import numpy as np\n",
    "print('numpy: {}'.format(np.__version__))\n",
    "# matplotlib\n",
    "\n",
    "\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "print('matplotlib: {}'.format(matplotlib.__version__)) # pandas\n",
    "import pandas as pd\n",
    "print('pandas: {}'.format(pd.__version__))\n",
    "# scikit-learn\n",
    "#import sklearn\n",
    "#print('sklearn: {}'.format(sklearn.__version__))\n",
    "#import xlrd\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import sklearn\n",
    "print('sklearn: {}'.format(sklearn.__version__))\n",
    "#import xlrd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import Lasso, Ridge  \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.feature_selection import RFE\n",
    "#import xgboost as xgb\n",
    "from sklearn import cross_validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import cross_validation #might be model_selection <--- this is the new one\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing \n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../cspython/test.pkl', 'rb') as f: \n",
    "     d = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_data = process_scrapped(d)\n",
    "overview, big_data = big_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e66048a5-8a32-477d-bae6-aea235e1b50e',\n",
       " '31e7fb31-a1f4-40f6-9f42-3652d95438cf',\n",
       " '4042df67-b86c-4583-abdf-ceb3c5b7ae31',\n",
       " 'a6c9a66d-1a36-4c36-9ee2-cf85abd5210b',\n",
       " 'c3e9af64-f0ff-448c-ad04-6a57e0480aab',\n",
       " '9515fdcb-472c-4590-8941-6cb9decd7c8c',\n",
       " '0d9622b1-db84-4698-b386-f52decfa9585',\n",
       " 'b7c6b7d9-f9ca-4f49-9a2f-348e1236ed4f',\n",
       " 'e9cab27e-26b7-4e17-bafe-380d6d45a315',\n",
       " 'fbe1812a-08fc-4a05-b4ee-1929591b7fb2']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key_being_used = big_data.keys()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'awp_kills':   Unnamed: 0  yay dephh ANDROID-X23  ptr  FNS\n",
       "  0        ryx  0:0   0:1         0:0  0:1  0:0\n",
       "  1       Hiko  0:0   0:2         0:0  0:2  0:0\n",
       "  2       SicK  1:0   2:2         0:0  0:3  0:0\n",
       "  3       vice  0:0   0:0         0:0  0:2  0:0\n",
       "  4     cadiaN  0:0   0:1         1:0  0:2  0:0,\n",
       "  'first_kills':   Unnamed: 0  yay dephh ANDROID-X23  ptr  FNS\n",
       "  0        ryx  1:0   0:0         1:2  0:1  0:0\n",
       "  1       Hiko  1:0   1:1         0:1  1:0  0:0\n",
       "  2       SicK  1:0   1:1         0:0  0:1  0:1\n",
       "  3       vice  0:0   0:0         0:1  3:0  1:0\n",
       "  4     cadiaN  1:0   1:0         1:0  0:1  0:1,\n",
       "  'total_team_kda':   Unnamed: 0  Unnamed: 1  Unnamed: 2  Unnamed: 3\n",
       "  0      Kills          90         NaN          70\n",
       "  1     Deaths          70         NaN          90\n",
       "  2    Assists          13         NaN          14,\n",
       "  'who_kill_who':   Unnamed: 0  yay dephh ANDROID-X23  ptr  FNS\n",
       "  0        ryx  4:3   1:7         5:4  1:3  1:2\n",
       "  1       Hiko  2:4   3:5         0:4  2:2  6:4\n",
       "  2       SicK  4:1   5:4         2:2  2:5  2:7\n",
       "  3       vice  4:1   5:4         2:4  6:3  3:2\n",
       "  4     cadiaN  3:7   2:3         3:2  1:3  1:4},\n",
       " {'awp_kills':   Unnamed: 0  yay dephh ANDROID-X23  ptr  FNS\n",
       "  0        ryx  0:0   0:0         0:0  0:0  0:0\n",
       "  1       Hiko  0:0   0:0         0:0  0:2  0:0\n",
       "  2       SicK  0:0   0:0         0:0  1:1  1:0\n",
       "  3       vice  0:0   0:0         0:0  0:0  0:0\n",
       "  4     cadiaN  3:0   2:0         2:0  1:4  1:0,\n",
       "  'first_kills':   Unnamed: 0  yay dephh ANDROID-X23  ptr  FNS\n",
       "  0        ryx  1:0   0:1         0:0  0:0  0:0\n",
       "  1       Hiko  0:0   1:1         0:1  1:1  0:1\n",
       "  2       SicK  1:1   0:0         0:1  0:1  0:0\n",
       "  3       vice  1:1   0:0         0:2  0:0  0:0\n",
       "  4     cadiaN  1:0   0:1         0:1  0:1  0:0,\n",
       "  'total_team_kda':   Unnamed: 0  Unnamed: 1  Unnamed: 2  Unnamed: 3\n",
       "  0      Kills          87         NaN          59\n",
       "  1     Deaths          59         NaN          87\n",
       "  2    Assists          16         NaN          13,\n",
       "  'who_kill_who':   Unnamed: 0  yay dephh ANDROID-X23  ptr  FNS\n",
       "  0        ryx  4:0   3:6         1:1  2:3  3:8\n",
       "  1       Hiko  3:2   6:2         0:3  1:4  1:6\n",
       "  2       SicK  3:2   3:3         3:5  2:4  3:3\n",
       "  3       vice  1:6   3:5         3:6  1:1  1:0\n",
       "  4     cadiaN  4:0   2:5         2:6  1:4  3:2}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_data[key_being_used]['match_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_dfs(big_data):\n",
    "    for l in range(len(big_data.keys())):\n",
    "        series_data = big_data[big_data.keys()[l]]\n",
    "        series_data_m = merge_matches(series_data)\n",
    "        series_data_mo = merge_overview(series_data_m, series_data)\n",
    "        series_data_mos = merge_scoreboards(series_data_mo, series_data)\n",
    "        if l == 0:\n",
    "            data = series_data_mos\n",
    "        else:\n",
    "            data = pd.concat([data, series_data_mos])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_matches(series_data):\n",
    "    for d in range(0,len(series_data['matches'])):\n",
    "        if d == 0:\n",
    "            series_data['matches'][d] = series_data['matches'][d].rename(index = str, columns={ series_data['matches'][d].columns[10] : \"team_A\", series_data['matches'][d].columns[11] : \"team_B\" })\n",
    "            series_data_m = series_data['matches'][d]\n",
    "        else:\n",
    "            series_data['matches'][d] = series_data['matches'][d].rename(index = str, columns={ series_data['matches'][d].columns[10] : \"team_A\", series_data['matches'][d].columns[11] : \"team_B\" })\n",
    "            series_data_m = pd.concat([series_data_m, series_data['matches'][d]])\n",
    "    return series_data_m\n",
    "    #should work for concact the matches together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_overview(series_data_m, series_data):\n",
    "    series_data['match_overview'] = series_data['match_overview'].rename(index = str, columns ={series_data['match_overview'].columns[4]: \"team_A_score\",series_data['match_overview'].columns[5]: \"team_B_score\"})\n",
    "    series_data_mo = pd.merge(series_data_m, series_data['match_overview'], on=['match_id', 'winner', 'map', 'series_id'])\n",
    "    return series_data_mo\n",
    "#works at merging matches with match_overviewb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_scoreboards(series_data_mo, series_data):    \n",
    "    for i in range(len(series_data['scoreboards'][0])):\n",
    "        series_data['scoreboards'][0][i]['match_num'] = i+1\n",
    "        series_data['scoreboards'][0][i] = series_data['scoreboards'][0][i].rename(index = str, columns={ series_data['scoreboards'][0][i].columns[0] : \"team_players\" })\n",
    "        series_data['scoreboards'][1][i]['match_num'] = i+1\n",
    "        series_data['scoreboards'][1][i] = series_data['scoreboards'][1][i].rename(index = str, columns={ series_data['scoreboards'][1][i].columns[0] : \"team_players\"})\n",
    "        new_df = pd.concat([series_data['scoreboards'][0][i], series_data['scoreboards'][1][i]])\n",
    "        if i == 0:\n",
    "            con_df = new_df\n",
    "        else:\n",
    "            con_df = pd.concat([con_df, new_df])\n",
    "    series_data_mos = pd.merge(series_data_mo, con_df, how='outer', on='match_num') \n",
    "    return series_data_mos\n",
    "\n",
    "       \n",
    "        \n",
    "#works at adding match_num to scoreboards\n",
    "        \n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = combine_dfs(big_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.concat([data,data['K-D'].str.split('-', 1, expand=True).rename(columns={0:'player_kill', 1:'player_death'})], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.apply(pd.to_numeric, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[['map', 'ending', 'CT', 'T', 'side_winner','winner', 'team_players']]= data[['map', 'ending', 'CT', 'T', 'side_winner','winner', 'team_players']].apply(lambda x: pd.factorize(x)[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['KAST'] = data['KAST'].apply(lambda x : float(x.strip('%')) / 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data.select_dtypes(include = ['float64', 'int64', 'int32']).iloc[:, 0:].corr()\n",
    "plt.figure(figsize=(25, 25))\n",
    "sns.heatmap(corr, vmax=1, square=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ydata = data['winner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.drop('winner', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.drop('match_id', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.drop('series_id', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.drop('K-D', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = ydata.values\n",
    "X = data.values[:,0:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_folds = 10\n",
    "num_instances = len(X) \n",
    "seed = 7\n",
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def local_cv(model, params):                             #KFOLD WITH GRID SEARCH\n",
    "    param_grid = params\n",
    "    kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "    grid_result = grid.fit(X, y)\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    for params, mean_score, scores in grid_result.grid_scores_:\n",
    "        print(\"%f (%f) with: %r\" % (scores.mean(), scores.std(), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_folds = 10\n",
    "num_instances = len(X) \n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "model = GradientBoostingClassifier()\n",
    "params = {\n",
    " 'max_depth':[4,6,8,10,12,16],\n",
    " 'n_estimators':[20,30,50,80,100],\n",
    "'learning_rate':[.1,.01,.001]}\n",
    "local_cv(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "#models.append(('LR', LogisticRegression()))\n",
    "#models.append(('LASSO', Lasso())) \n",
    "#models.append(('Ridge', Ridge())) \n",
    "#models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "#models.append(('NB', GaussianNB()))\n",
    "#models.append(('CART', DecisionTreeClassifier())) \n",
    "#models.append(('KNeighborsClassifier', KNeighborsClassifier())) \n",
    "#models.append(('XGBClassifier', xgb.XGBClassifier()))\n",
    "models.append(('GradientBoostingClassifier', GradientBoostingClassifier()))\n",
    "#models.append(('AdaBoostClassifier', AdaBoostClassifier()))\n",
    "#models.append(('RandomForestClassifier', RandomForestClassifier()))\n",
    "#models.append(('ExtraTreesClassifier', ExtraTreesClassifier()))\n",
    "models.append(('DecisionTreeClassifier', DecisionTreeClassifier()))\n",
    "models.append(('SVC', SVC()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    print '1'\n",
    "    kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "    print '2'\n",
    "    cv_results = cross_validation.cross_val_score(model, X, y, cv=kfold, scoring = scoring)\n",
    "    print '3'\n",
    "    results.append(cv_results)\n",
    "    print '4'\n",
    "    names.append(name)\n",
    "    print '5'\n",
    "    model.fit(X, y)\n",
    "    print '6'\n",
    "    predicted = model.predict(X)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
