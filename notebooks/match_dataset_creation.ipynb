{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy: 0.19.1\n",
      "numpy: 1.12.1\n",
      "matplotlib: 2.0.2\n",
      "pandas: 0.20.3\n",
      "sklearn: 0.19.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SuperBug\\Anaconda2\\envs\\cs_project\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from cspython.merging_processing import combine_dfs\n",
    "import cPickle as pkl\n",
    "from cspython.scraper import modifiedSoup\n",
    "from cspython.data_processing import process_scrapped\n",
    "import cPickle as pkl\n",
    "import sys\n",
    "sys.setrecursionlimit(15000)\n",
    "\n",
    "import cspython.analysis as a\n",
    "import scipy\n",
    "print('scipy: {}'.format(scipy.__version__)) # numpy\n",
    "import numpy as np\n",
    "print('numpy: {}'.format(np.__version__))\n",
    "# matplotlib\n",
    "\n",
    "\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "print('matplotlib: {}'.format(matplotlib.__version__)) # pandas\n",
    "import pandas as pd\n",
    "print('pandas: {}'.format(pd.__version__))\n",
    "# scikit-learn\n",
    "#import sklearn\n",
    "#print('sklearn: {}'.format(sklearn.__version__))\n",
    "#import xlrd\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import sklearn\n",
    "print('sklearn: {}'.format(sklearn.__version__))\n",
    "#import xlrd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import Lasso, Ridge  \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.feature_selection import RFE\n",
    "import xgboost as xgb\n",
    "from sklearn import cross_validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import cross_validation #might be model_selection <--- this is the new one\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing \n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import pdb\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import cross_validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../cspython/esl_teams.pkl', 'rb') as f: \n",
    "     d = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "big_data = process_scrapped(d)\n",
    "overview, big_data = big_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = combine_dfs(overview, big_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_opponent_team_col(data):\n",
    "    data.loc[:,'player_team_opponent'] = np.nan\n",
    "    data.loc[(data['team_A_name'] != data['player_team_name']),'player_team_opponent'] = data.loc[:,'team_A_name']\n",
    "    data.loc[(data['team_B_name'] != data['player_team_name']),'player_team_opponent'] = data.loc[:,'team_B_name']\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_fwa_dr_columns(data, col_list):  # first k , awp, who, divided by rounds \n",
    "    columns = pd.Series(data.columns)\n",
    "    for a in col_list:\n",
    "        col = columns[columns.str.contains(a)]\n",
    "        data[a+'_sum_dr'] = data[col].convert_objects(convert_numeric = True).sum(axis = 1) / (data['team_A_score'] + data['team_B_score'])*100\n",
    "    data.loc[:, data.columns != 'date'] = data.loc[:, data.columns != 'date'].apply(pd.to_numeric, errors='ignore')\n",
    "    return data\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_player_columns(data):\n",
    "    names = data.nicknames.unique()\n",
    "    for a in names:\n",
    "        data.loc[:,a] = 0\n",
    "        data.loc[data.loc[:,'nicknames'] == a, a] = 5   # its 5 so that when you group by team it becomes 1 \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_nummeric_and_group_as_match(data):\n",
    "    r = data.loc[:, data.columns != 'date'].apply(pd.to_numeric, errors='ignore')\n",
    "    r['date'] = data.date\n",
    "    data = r\n",
    "    data = data.fillna(0)\n",
    "    data_match = data.groupby(['match_id', 'player_team_name', 'date', 'team_A_name', 'team_B_name', 'series_id', 'map', 'winner_of_match', 'loser_of_match','player_team_opponent']).mean()\n",
    "    data_match = pd.DataFrame(data_match)\n",
    "    data_match = data_match.reset_index()\n",
    "    return data_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def player_based_column_making(data): # these are the functions that are non historic and arent grouped by match_id\n",
    "    col_list = ['first_kills', 'who_kill_who', 'awp_kills']\n",
    "    data = create_opponent_team_col(data)\n",
    "    data = create_fwa_dr_columns(data, col_list)\n",
    "    data = create_player_columns(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_historic_data(data):\n",
    "    col_list = ['first_kills', 'who_kill_who','awp_kills']\n",
    "    data = create_fwadr_his(data, col_list)\n",
    "    data = create_matches_count(data)\n",
    "    data = create_avdamage_his(data)\n",
    "    data = create_avdamage_map_his(data)\n",
    "    data = create_faw_map_his(data, col_list)\n",
    "    return data\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_matches_count(data): # how many matches a team has played\n",
    "    teams = list(data.player_team_name.unique())\n",
    "    new_group = pd.DataFrame()\n",
    "    for a in teams:   \n",
    "        data_team = data.loc[data.loc[:,'player_team_name'] == a, ].sort_values(by='date',ascending=True)\n",
    "        grouping = data_team.groupby(['player_team_name','date','match_id'])['ADR'].count()\n",
    "        grouping = pd.DataFrame(grouping)\n",
    "        grouping = grouping.reset_index()\n",
    "        grouping.loc[:,'ADR'] = grouping.loc[:,'ADR'].expanding(min_periods=1, freq=None, center=False, axis=0).sum()\n",
    "        grouping = grouping.rename(index=str, columns={'ADR': 'matches_played_team'})\n",
    "        new_group = pd.concat([new_group, grouping])\n",
    "    data = pd.merge(data, new_group, on = ['player_team_name','match_id','date'])\n",
    "\n",
    "    return data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_avdamage_his(data):  # column with historic average damage of individual !!!\n",
    "    teams = list(data.player_team_name.unique())\n",
    "    new_group = pd.DataFrame()\n",
    "    for a in teams:   \n",
    "        data_team = data.loc[data.loc[:,'player_team_name'] == a, ].sort_values(by='date',ascending=True)\n",
    "        grouping = data_team.groupby(['player_team_name','date','match_id'])['ADR'].max()\n",
    "        grouping = pd.DataFrame(grouping)\n",
    "        grouping = grouping.reset_index()\n",
    "        grouping.loc[:,'ADR'] = grouping.loc[:,'ADR'].expanding(min_periods=1, freq=None, center=False, axis=0).mean()\n",
    "        grouping = grouping.rename(index=str, columns={'ADR': 'ADR_hist'})\n",
    "        new_group = pd.concat([new_group, grouping])\n",
    "    data = pd.merge(data, new_group, on = ['player_team_name','match_id','date'])\n",
    "\n",
    "    return data\n",
    "   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_avdamage_map_his(data):# historic average damage of individual for each map !!!\n",
    "    teams = list(data.player_team_name.unique())\n",
    "    maps = list(data.map.unique())\n",
    "    new_group = pd.DataFrame()\n",
    "    for a in maps:\n",
    "        for b in teams:   \n",
    "            data_team = data.loc[(data.loc[:,'player_team_name'] == b) & (data.loc[:,'map'] == a), ].sort_values(by='date',ascending=True)\n",
    "            grouping = data_team.groupby(['player_team_name','match_id'])['ADR'].max()\n",
    "            grouping = pd.DataFrame(grouping)\n",
    "            grouping = grouping.reset_index()\n",
    "            grouping.loc[:,'ADR'] = grouping.loc[:,'ADR'].expanding(min_periods=1, freq=None, center=False, axis=0).mean()\n",
    "            grouping = grouping.rename(index=str, columns={'ADR': 'ADR_hist_on_map'})\n",
    "            new_group = pd.concat([new_group, grouping])\n",
    "    \n",
    "    data = pd.merge(data, new_group, on = ['match_id','player_team_name'])\n",
    "\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_fwadr_his(data, col_list):\n",
    "    teams = list(data.player_team_name.unique())\n",
    "    for b in col_list:\n",
    "        new_group = pd.DataFrame()\n",
    "        for a in teams:   \n",
    "            data_team = data.loc[data.loc[:,'player_team_name'] == a, ].sort_values(by='date',ascending=True)\n",
    "            grouping = data_team.groupby(['player_team_name','date','match_id'])[b+'_sum_dr'].max()\n",
    "            grouping = pd.DataFrame(grouping)\n",
    "            grouping = grouping.reset_index()\n",
    "            grouping.loc[:,b +'_sum_dr'] = grouping.loc[:,b +'_sum_dr'].expanding(min_periods=1, freq=None, center=False, axis=0).mean()\n",
    "            grouping = grouping.rename(index=str, columns={b +'_sum_dr': b + '_sum_dr_hist'})\n",
    "            new_group = pd.concat([new_group, grouping])\n",
    "        data = pd.merge(data, new_group, on = ['player_team_name','match_id','date'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_faw_map_his(data, col_list):\n",
    "    teams = list(data.player_team_name.unique())\n",
    "    maps = list(data.map.unique())\n",
    "    for b in col_list:\n",
    "        new_group = pd.DataFrame()\n",
    "        for i in maps:\n",
    "            for a in teams:   \n",
    "                data_team = data.loc[(data.loc[:,'player_team_name'] == a) & (data.loc[:,'map'] == i), ].sort_values(by='date',ascending=True)\n",
    "                grouping = data_team.groupby(['player_team_name','match_id'])[b+'_sum_dr'].max()\n",
    "                grouping = pd.DataFrame(grouping)\n",
    "                grouping = grouping.reset_index()\n",
    "                grouping.loc[:,b +'_sum_dr'] = grouping.loc[:,b +'_sum_dr'].expanding(min_periods=1, freq=None, center=False, axis=0).mean()\n",
    "                grouping = grouping.rename(index=str, columns={b +'_sum_dr': b + '_sum_dr_hist_on_map'})\n",
    "                new_group = pd.concat([new_group, grouping])\n",
    "                \n",
    "        data = pd.merge(data, new_group, on = ['match_id','player_team_name'])\n",
    "    return data   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def match_dataset_creation(data):  #creates player based columns, then groups to allow for historic match based columns\n",
    "    data = player_based_column_making(data)\n",
    "    data = apply_nummeric_and_group_as_match(data)\n",
    "    data = create_historic_data(data)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data = match_dataset_creation(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data.to_pickle(\"data_converged_historic.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"data_converged_historic.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.loc[(data.loc[:,'player_team_name'] == 'Cloud9') & (data.loc[:,'map'] == 'Inferno'),].sort_values(by='date',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  FUNCTIONS BELOW HERE NEED TO BE WORKED ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_map_win_loss_his(data):  # team total win and loses on map with total times played on map !4!\n",
    "    maps = data.map.unique()\n",
    "    match_id = data.match_id.unique()\n",
    "    for a in maps:\n",
    "        data[a + \"_win_his\"] = 0\n",
    "        data[a + \"_loss_his\"] = 0\n",
    "        data[a + \"_total_played\"] = 0\n",
    "    for a in match_id:\n",
    "        map_for_match = data.loc[(data['match_id'] == a) ,'map'].unique()\n",
    "        winner_of_map = data.loc[(data['match_id'] == a), 'winner_of_match'].unique()\n",
    "        loser_of_map = data.loc[(data['match_id'] == a), 'loser_of_match'].unique()\n",
    "        data.loc[(data['player_team_name'] == winner_of_map[0]), [map_for_match[0] + \"_win_his\", map_for_match[0] +'_total_played']] += 1\n",
    "        data.loc[(data['player_team_name'] == loser_of_map[0]), [map_for_match[0] + \"_loss_his\", map_for_match[0] +'_total_played']] += 1 \n",
    "       \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_map_win_his_per(data): #percentage team total win and loses on map !5!\n",
    "    teams = data.player_team_name.unique()\n",
    "    maps = data.map.unique()\n",
    "    for a in maps:\n",
    "        data[a + '_win_perc_map'] = 0\n",
    "        for b in teams:\n",
    "            pg = (data.player_team_name == b) \n",
    "            data.loc[pg,a + '_win_perc_map'] = data.loc[pg, a + \"_win_his\"].unique()[0] / float((data.loc[pg, a + \"_win_his\"].unique()[0] + data.loc[pg, a + \"_loss_his\"].unique()[0])) * 100 \n",
    "    data = data.fillna(0)        \n",
    "    return data    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_rounds_won_vs_team_his(data): # team rounds won vs another team    !6!\n",
    "    grouping = data.groupby(['match_id','map','team_A_name','team_B_name', 'team_A_score', 'team_B_score'])['round_num'].count()\n",
    "    grouping = pd.DataFrame(grouping)\n",
    "    grouping = grouping.add_suffix('_Count').reset_index()\n",
    "    grouping = grouping.groupby(['team_A_name', 'team_B_name']).sum()\n",
    "    grouping = pd.DataFrame(grouping)\n",
    "    grouping = grouping.add_suffix('_Count').reset_index()\n",
    "    forward = grouping.team_A_name+grouping.team_B_name\n",
    "    reverse = grouping.team_B_name+grouping.team_A_name\n",
    "    for idx, val in enumerate(forward):\n",
    "        for idx2, val2 in enumerate(reverse):\n",
    "            if val == val2 and idx < idx2:\n",
    "                grouping.loc[idx,'team_A_score_Count'] += grouping.loc[idx2,'team_B_score_Count']\n",
    "                grouping.loc[idx,'team_B_score_Count'] += grouping.loc[idx2,'team_A_score_Count']\n",
    "                grouping.loc[idx2,'team_B_score_Count'] = grouping.loc[idx,'team_A_score_Count']\n",
    "                grouping.loc[idx2,'team_A_score_Count'] = grouping.loc[idx,'team_B_score_Count']\n",
    "            elif val == val2 and idx > idx2:\n",
    "                grouping.loc[idx2,'team_B_score_Count'] = grouping.loc[idx,'team_A_score_Count']\n",
    "                grouping.loc[idx2,'team_A_score_Count'] = grouping.loc[idx,'team_B_score_Count']\n",
    "    \n",
    "    grouping = grouping.drop('round_num_Count_Count', axis = 1)\n",
    "    col1 = list(grouping.team_A_name.unique())\n",
    "    col2  = list(grouping.team_B_name.unique())\n",
    "    col = col1 + col2\n",
    "    col = list(set(col))\n",
    "    data = pd.merge(data,grouping, on=['team_A_name', 'team_B_name']) \n",
    "    for a in col:\n",
    "        data['rd_total_his_'+ a] = 0\n",
    "        data.loc[(data.player_team_name != a) & (data.team_A_name == a) , 'rd_total_his_'+ a]=data.team_B_score_Count\n",
    "        data.loc[(data.player_team_name != a) & (data.team_B_name == a) , 'rd_total_his_'+ a]=data.team_A_score_Count\n",
    "        bgrouping = data.groupby(['player_team_name'])['rd_total_his_'+ a].max()\n",
    "        bgrouping = pd.DataFrame(bgrouping)\n",
    "        bgrouping = bgrouping.reset_index()\n",
    "        data = data.drop('rd_total_his_'+ a, axis = 1)\n",
    "        data = pd.merge(data, bgrouping, on = 'player_team_name')\n",
    "       \n",
    "    return data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_total_team_rd_map_his(data):\n",
    "    grouping = data.groupby(['map','team_A_name', 'team_A_score'])['round_num'].count()\n",
    "    grouping = pd.DataFrame(grouping)\n",
    "    grouping = grouping.add_suffix('_Count').reset_index()\n",
    "    grouping = grouping.groupby(['map','team_A_name'])[ 'team_A_score'].sum()\n",
    "    grouping = pd.DataFrame(grouping)\n",
    "    grouping = grouping.add_suffix('_Count').reset_index()\n",
    "    fgrouping = data.groupby(['player_team_name','map','team_B_name', 'team_B_score'])['round_num'].count()\n",
    "    fgrouping = pd.DataFrame(fgrouping)\n",
    "    fgrouping = fgrouping.add_suffix('_Count').reset_index()\n",
    "    fgrouping = fgrouping.groupby(['map','team_B_name'])[ 'team_B_score'].sum()\n",
    "    fgrouping = pd.DataFrame(fgrouping)\n",
    "    fgrouping = fgrouping.add_suffix('_Count').reset_index()\n",
    "    fgrouping = fgrouping.rename(index=str, columns={\"team_B_name\": \"team_A_name\", 'team_B_score_Count': 'team_A_score_Count'})\n",
    "    merged = pd.concat([grouping, fgrouping], axis = 0)\n",
    "    merged.groupby(['map', 'team_A_name'])['team_A_score_Count'].sum()\n",
    "    merged = pd.DataFrame(merged)\n",
    "    merged = merged.reset_index(drop = True)\n",
    "    merged = merged.rename(index=str, columns={\"team_A_name\": \"player_team_name\", \"team_A_score_Count\": 'total_team_rd_map'})\n",
    "    merged = merged.groupby(['player_team_name', 'map']).sum()\n",
    "    merged = pd.DataFrame(merged)\n",
    "    merged = merged.reset_index()\n",
    "    for a in list(merged.map.unique()):\n",
    "        merged.loc[:,'total_team_rd_'+ a] = 0\n",
    "        merged.loc[(merged.loc[:, 'map'] == a), 'total_team_rd_'+ a] = merged.loc[:,'total_team_rd_map']\n",
    "        ok_map = merged.groupby(['player_team_name'])['total_team_rd_'+ a].max()\n",
    "        ok_map = pd.DataFrame(ok_map)\n",
    "        ok_map = ok_map.reset_index()\n",
    "        data = pd.merge(data, ok_map, on = 'player_team_name')\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#FUNCTIONS ABOVE HERE NEED TO BE WORKED ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data.to_pickle(\"data_converged_changed.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_list = ['first_kills', 'who_kill_who','awp_kills']\n",
    "data = create_fwa_dr_columns(data, col_list)\n",
    "data = create_fwadr_his(data,col_list)\n",
    "data = create_avdamage_his(data)\n",
    "data = create_map_win_loss_his(data)\n",
    "data = create_map_win_his_per(data)\n",
    "data = create_rounds_won_vs_team_his(data)\n",
    "data = create_total_team_rd_map_his(data)\n",
    "data = create_avdamage_map_his(data)\n",
    "data = create_faw_map_his(data, col_list)\n",
    "data = create_matches_count(data)\n",
    "data = create_opponent_team_col(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
