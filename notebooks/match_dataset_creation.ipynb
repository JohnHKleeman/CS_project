{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy: 0.19.1\n",
      "numpy: 1.13.3\n",
      "pandas: 0.22.0\n",
      "matplotlib: 2.1.0\n",
      "sklearn: 0.19.1\n"
     ]
    }
   ],
   "source": [
    "import sys, pdb, warnings, scipy, matplotlib, sklearn, itertools\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cPickle as pkl\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, Ridge\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import preprocessing \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style(\"whitegrid\")\n",
    "sys.setrecursionlimit(15000)\n",
    "pd.set_option('display.max_columns', 300)\n",
    "%matplotlib inline\n",
    "\n",
    "print('scipy: {}'.format(scipy.__version__))\n",
    "print('numpy: {}'.format(np.__version__))\n",
    "print('pandas: {}'.format(pd.__version__))\n",
    "print('matplotlib: {}'.format(matplotlib.__version__)) \n",
    "print('sklearn: {}'.format(sklearn.__version__))\n",
    "\n",
    "#our modules see: CS_Project/cspython directory\n",
    "from cspython.scraper import modifiedSoup\n",
    "from cspython.data_processing import process_scrapped\n",
    "import cspython.analysis as a\n",
    "from cspython.merging_processing import combine_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "with open('../cspython/esl_teams.pkl', 'rb') as f: \n",
    "     d = pkl.load(f)\n",
    "        \n",
    "big_data = process_scrapped(d)\n",
    "data = combine_dfs(*big_data)\n",
    "\"\"\"\n",
    "\n",
    "with open('big_data.pkl', 'rb') as f:\n",
    "    big_data = pkl.load(f)\n",
    "    \n",
    "data = combine_dfs(*big_data)\n",
    "data.sort_values('date', inplace=True)\n",
    "data.index = range(len(data))\n",
    "overview = big_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_opponent_team_col(data):\n",
    "    data.loc[:,'player_team_opponent'] = np.nan\n",
    "    data.loc[(data['team_A_name'] != data['player_team_name']),'player_team_opponent'] = data.loc[:,'team_A_name']\n",
    "    data.loc[(data['team_B_name'] != data['player_team_name']),'player_team_opponent'] = data.loc[:,'team_B_name']\n",
    "    return data\n",
    "\n",
    "def create_fwa_dr_columns(data, col_list):  # first k , awp, who, divided by rounds \n",
    "    columns = pd.Series(data.columns)\n",
    "    for a in col_list:\n",
    "        col = columns[columns.str.contains(a)]\n",
    "        data[a+'_sum_dr'] = data[col].convert_objects(convert_numeric = True).sum(axis = 1) / (data['team_A_score'] + data['team_B_score'])*100\n",
    "    data.loc[:, data.columns != 'date'] = data.loc[:, data.columns != 'date'].apply(pd.to_numeric, errors='ignore')\n",
    "    return data\n",
    "\n",
    "def create_player_columns(data):\n",
    "    names = data.nicknames.unique()\n",
    "    for a in names:\n",
    "        data.loc[:,a] = 0\n",
    "        data.loc[data.loc[:,'nicknames'] == a, a] = 5   # its 5 so that when you group by team it becomes 1 \n",
    "    return data\n",
    "    \n",
    "def apply_nummeric_and_group_as_match(data):\n",
    "    r = data.loc[:, data.columns != 'date'].apply(pd.to_numeric, errors='ignore')\n",
    "    r['date'] = data.date\n",
    "    data = r\n",
    "    data = data.fillna(0)\n",
    "    data_match = data.groupby(['match_id', 'player_team_name', 'date', 'team_A_name', 'team_B_name', 'series_id', 'map', 'winner_of_match', 'loser_of_match','player_team_opponent']).mean()\n",
    "    data_match = pd.DataFrame(data_match)\n",
    "    data_match = data_match.reset_index()\n",
    "    return data_match\n",
    "\n",
    "def player_based_column_making(data): # these are the functions that are non historic and arent grouped by match_id\n",
    "    col_list = ['first_kills', 'who_kill_who', 'awp_kills']\n",
    "    data = create_opponent_team_col(data)\n",
    "    data = create_fwa_dr_columns(data, col_list)\n",
    "    data = create_player_columns(data)\n",
    "    return data\n",
    "\n",
    "def create_historic_data(data):\n",
    "    col_list = ['first_kills', 'who_kill_who','awp_kills']\n",
    "    data = create_fwadr_his(data, col_list)\n",
    "    data = create_matches_count(data)\n",
    "    data = create_avdamage_his(data)\n",
    "    data = create_avdamage_map_his(data)\n",
    "    data = create_faw_map_his(data, col_list)\n",
    "    return data\n",
    "\n",
    "def create_matches_count(data): # how many matches a team has played\n",
    "    teams = list(data.player_team_name.unique())\n",
    "    new_group = pd.DataFrame()\n",
    "    for a in teams:   \n",
    "        data_team = data.loc[data.loc[:,'player_team_name'] == a, ].sort_values(by='date',ascending=True)\n",
    "        grouping = data_team.groupby(['player_team_name','date','match_id'])['ADR'].count()\n",
    "        grouping = pd.DataFrame(grouping)\n",
    "        grouping = grouping.reset_index()\n",
    "        grouping.loc[:,'ADR'] = grouping.loc[:,'ADR'].expanding(min_periods=1, freq=None, center=False, axis=0).sum()\n",
    "        grouping = grouping.rename(index=str, columns={'ADR': 'matches_played_team'})\n",
    "        new_group = pd.concat([new_group, grouping])\n",
    "    data = pd.merge(data, new_group, on = ['player_team_name','match_id','date'])\n",
    "\n",
    "    return data\n",
    "\n",
    "def create_avdamage_his(data):  # column with historic average damage of individual !!!\n",
    "    teams = list(data.player_team_name.unique())\n",
    "    new_group = pd.DataFrame()\n",
    "    for a in teams:   \n",
    "        data_team = data.loc[data.loc[:,'player_team_name'] == a, ].sort_values(by='date',ascending=True)\n",
    "        grouping = data_team.groupby(['player_team_name','date','match_id'])['ADR'].max()\n",
    "        grouping = pd.DataFrame(grouping)\n",
    "        grouping = grouping.reset_index()\n",
    "        grouping.loc[:,'ADR'] = grouping.loc[:,'ADR'].expanding(min_periods=1, freq=None, center=False, axis=0).mean()\n",
    "        grouping = grouping.rename(index=str, columns={'ADR': 'ADR_hist'})\n",
    "        new_group = pd.concat([new_group, grouping])\n",
    "    data = pd.merge(data, new_group, on = ['player_team_name','match_id','date'])\n",
    "\n",
    "    return data\n",
    "\n",
    "def create_avdamage_map_his(data):# historic average damage of individual for each map !!!\n",
    "    teams = list(data.player_team_name.unique())\n",
    "    maps = list(data.map.unique())\n",
    "    new_group = pd.DataFrame()\n",
    "    for a in maps:\n",
    "        for b in teams:   \n",
    "            data_team = data.loc[(data.loc[:,'player_team_name'] == b) & (data.loc[:,'map'] == a), ].sort_values(by='date',ascending=True)\n",
    "            grouping = data_team.groupby(['player_team_name','match_id'])['ADR'].max()\n",
    "            grouping = pd.DataFrame(grouping)\n",
    "            grouping = grouping.reset_index()\n",
    "            grouping.loc[:,'ADR'] = grouping.loc[:,'ADR'].expanding(min_periods=1, freq=None, center=False, axis=0).mean()\n",
    "            grouping = grouping.rename(index=str, columns={'ADR': 'ADR_hist_on_map'})\n",
    "            new_group = pd.concat([new_group, grouping])\n",
    "    \n",
    "    data = pd.merge(data, new_group, on = ['match_id','player_team_name'])\n",
    "\n",
    "    return data\n",
    "\n",
    "def create_fwadr_his(data, col_list):\n",
    "    teams = list(data.player_team_name.unique())\n",
    "    for b in col_list:\n",
    "        new_group = pd.DataFrame()\n",
    "        for a in teams:   \n",
    "            data_team = data.loc[data.loc[:,'player_team_name'] == a, ].sort_values(by='date',ascending=True)\n",
    "            grouping = data_team.groupby(['player_team_name','date','match_id'])[b+'_sum_dr'].max()\n",
    "            grouping = pd.DataFrame(grouping)\n",
    "            grouping = grouping.reset_index()\n",
    "            grouping.loc[:,b +'_sum_dr'] = grouping.loc[:,b +'_sum_dr'].expanding(min_periods=1, freq=None, center=False, axis=0).mean()\n",
    "            grouping = grouping.rename(index=str, columns={b +'_sum_dr': b + '_sum_dr_hist'})\n",
    "            new_group = pd.concat([new_group, grouping])\n",
    "        data = pd.merge(data, new_group, on = ['player_team_name','match_id','date'])\n",
    "    return data\n",
    "\n",
    "def create_faw_map_his(data, col_list):\n",
    "    teams = list(data.player_team_name.unique())\n",
    "    maps = list(data.map.unique())\n",
    "    for b in col_list:\n",
    "        new_group = pd.DataFrame()\n",
    "        for i in maps:\n",
    "            for a in teams:   \n",
    "                data_team = data.loc[(data.loc[:,'player_team_name'] == a) & (data.loc[:,'map'] == i), ].sort_values(by='date',ascending=True)\n",
    "                grouping = data_team.groupby(['player_team_name','match_id'])[b+'_sum_dr'].max()\n",
    "                grouping = pd.DataFrame(grouping)\n",
    "                grouping = grouping.reset_index()\n",
    "                grouping.loc[:,b +'_sum_dr'] = grouping.loc[:,b +'_sum_dr'].expanding(min_periods=1, freq=None, center=False, axis=0).mean()\n",
    "                grouping = grouping.rename(index=str, columns={b +'_sum_dr': b + '_sum_dr_hist_on_map'})\n",
    "                new_group = pd.concat([new_group, grouping])\n",
    "                \n",
    "        data = pd.merge(data, new_group, on = ['match_id','player_team_name'])\n",
    "    return data   \n",
    "\n",
    "def match_dataset_creation(data):  #creates player based columns, then groups to allow for historic match based columns\n",
    "    data = player_based_column_making(data)\n",
    "    data = apply_nummeric_and_group_as_match(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1208, 440)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "data = match_dataset_creation(data)\n",
    "data.to_pickle(\"match_dataset.pkl\")\n",
    "\"\"\"\n",
    "\n",
    "data = pd.read_pickle(\"match_dataset.pkl\")\n",
    "print data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_map_win_loss_total(df): #this function assumes the df contains only rows from one team\n",
    "    team_name = df.player_team_name.iloc[0]\n",
    "    maps = df.map.unique()\n",
    "    \n",
    "    for map_name in maps:\n",
    "        df[map_name + \"_win_his\"] = np.nan\n",
    "        df[map_name + \"_loss_his\"] = np.nan\n",
    "        df[map_name + \"_total_played\"] = np.nan\n",
    "        \n",
    "    grouped = df.groupby('map')\n",
    "    for map_name, map_df in grouped:\n",
    "        played = pd.Series(range(1,len(map_df)+1), index=map_df.index)\n",
    "        won = (map_df.winner_of_match == team_name).expanding(1).sum()\n",
    "        lost = played - won\n",
    "        \n",
    "        df.loc[map_df.index, map_name + '_total_played'] = played\n",
    "        df.loc[map_df.index, map_name + '_win_his'] = won\n",
    "        df.loc[map_df.index, map_name + '_loss_his'] = lost\n",
    "        \n",
    "        df.loc[:, map_name + '_total_played'].fillna(method='ffill', inplace=True)\n",
    "        df.loc[:, map_name + '_win_his'].fillna(method='ffill', inplace=True)\n",
    "        df.loc[:, map_name + '_loss_his'].fillna(method='ffill', inplace=True)\n",
    "        \n",
    "        df.loc[:, map_name + '_total_played'].fillna(0, inplace=True)\n",
    "        df.loc[:, map_name + '_win_his'].fillna(0, inplace=True)\n",
    "        df.loc[:, map_name + '_loss_his'].fillna(0, inplace=True)\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_map_win_loss_and_per_his_columns(data):  # team total win and loses on map with total times played on map !4!\n",
    "    data.sort_values('date', inplace=True)\n",
    "    data.index = range(len(data))\n",
    "    original_col_order = data.columns.tolist()\n",
    "    data = data.groupby('player_team_name').apply(count_map_win_loss_total)\n",
    "    new_cols = data.columns[~data.columns.isin(original_col_order)].tolist()\n",
    "    data = data.loc[:, original_col_order + new_cols]\n",
    "    for map_name in data.map.unique():\n",
    "        data.loc[:, map_name + '_win_perc_map'] = data.loc[:, map_name + '_win_his']/data.loc[:, map_name + '_total_played']\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  FUNCTIONS BELOW HERE NEED TO BE WORKED ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Rounds won and lost in current match\n",
    "def create_rounds_won_rounds_loss_columns(data):\n",
    "    team_A_rounds = data.loc[data.player_team_name == data.team_A_name, 'team_A_score']\n",
    "    team_B_rounds = data.loc[data.player_team_name == data.team_B_name, 'team_B_score']\n",
    "    rounds_won = pd.concat([team_A_rounds, team_B_rounds])\n",
    "    data.loc[:, 'rounds_won'] = rounds_won\n",
    "    \n",
    "    team_A_rounds = data.loc[data.player_team_name == data.team_B_name, 'team_A_score']\n",
    "    team_B_rounds = data.loc[data.player_team_name == data.team_A_name, 'team_B_score']\n",
    "    rounds_lost = pd.concat([team_A_rounds, team_B_rounds])\n",
    "    data.loc[:, 'rounds_lost'] = rounds_lost\n",
    "    \n",
    "    return data\n",
    "\n",
    "#running total of rounds won/lost vs opponent\n",
    "\n",
    "def count_rounds_won_vs_opponent(df): #parsing a df of 1 team\n",
    "    grouped = df.groupby('player_team_opponent')\n",
    "    for opponent, opponent_df in grouped:\n",
    "        won_his = opponent_df.loc[:, 'rounds_won'].expanding(1).sum()\n",
    "        loss_his = opponent_df.loc[:,'rounds_lost'].expanding(1).sum()\n",
    "        \n",
    "        df.loc[opponent_df.index, 'rounds_won_vs_'+opponent] = won_his\n",
    "        df.loc[opponent_df.index, 'rounds_loss_vs_'+opponent] = loss_his\n",
    "        \n",
    "        df.loc[:, 'rounds_won_vs_'+opponent].fillna(method='ffill', inplace=True)\n",
    "        df.loc[:, 'rounds_loss_vs_'+opponent].fillna(method='ffill', inplace=True)\n",
    "        \n",
    "        df.loc[:, 'rounds_won_vs_'+opponent].fillna(0, inplace=True)\n",
    "        df.loc[:, 'rounds_loss_vs_'+opponent].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_rounds_won_and_lost_vs_team_his(data): #applied to entire dataset\n",
    "    data.sort_values('date', inplace = True)\n",
    "    data = data.groupby('player_team_name').apply(count_rounds_won_vs_opponent)\n",
    "    return data\n",
    "\n",
    "\n",
    "def count_rounds_won_vs_opponent_on_map(df): # parsing a df of 1 team\n",
    "    opponent = df.player_team_opponent.values[0]\n",
    "    map_name = df.map.values[0]\n",
    "\n",
    "    won_his = df.loc[:, 'rounds_won'].expanding(1).sum()\n",
    "    loss_his = df.loc[:,'rounds_lost'].expanding(1).sum()\n",
    "        \n",
    "    df.loc[:, 'rounds_won_vs_'+opponent+'_on_'+map_name] = won_his\n",
    "    df.loc[:, 'rounds_loss_vs_'+opponent+'_on_'+map_name] = loss_his\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_rounds_won_and_lost_vs_team_by_map_his(data):\n",
    "    data.sort_values('date', inplace = True)\n",
    "    data = data.groupby(['player_team_name', 'player_team_opponent', 'map']).apply(count_rounds_won_vs_opponent_on_map)\n",
    "    \n",
    "    for team, opponent, map_name in itertools.product(data.player_team_name.unique(), data.player_team_opponent.unique(), data.map.unique()):\n",
    "        if 'rounds_won_vs_'+opponent+'_on_'+map_name not in data.columns:\n",
    "            data.loc['rounds_won_vs_'+opponent+'_on_'+map_name] = 0\n",
    "            data.loc['rounds_loss_vs_'+opponent+'_on_'+map_name] = 0\n",
    "            continue\n",
    "        col = data.loc[data.player_team_name == team, 'rounds_won_vs_'+opponent+'_on_'+map_name].fillna(method='ffill')\n",
    "        data.loc[data.player_team_name == team, 'rounds_won_vs_'+opponent+'_on_'+map_name] = col\n",
    "        col = data.loc[data.player_team_name == team, 'rounds_loss_vs_'+opponent+'_on_'+map_name].fillna(method='ffill')\n",
    "        data.loc[data.player_team_name == team, 'rounds_loss_vs_'+opponent+'_on_'+map_name] = col\n",
    "        col = data.loc[data.player_team_name == team, 'rounds_won_vs_'+opponent+'_on_'+map_name].fillna(0)\n",
    "        data.loc[data.player_team_name == team, 'rounds_won_vs_'+opponent+'_on_'+map_name] = col\n",
    "        col = data.loc[data.player_team_name == team, 'rounds_loss_vs_'+opponent+'_on_'+map_name].fillna(0)\n",
    "        data.loc[data.player_team_name == team, 'rounds_loss_vs_'+opponent+'_on_'+map_name] = col\n",
    "    return data\n",
    "    \n",
    "    \n",
    "def create_round_his_cols(data):\n",
    "    original_col_order = data.columns.tolist()\n",
    "    data = create_rounds_won_rounds_loss_columns(data)\n",
    "    data = create_rounds_won_and_lost_vs_team_his(data)\n",
    "    data = create_rounds_won_and_lost_vs_team_by_map_his(data)\n",
    "    new_cols = data.columns[~data.columns.isin(original_col_order)].tolist()\n",
    "    data = data.loc[:, original_col_order + new_cols]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle('aggregated_dataset.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tester = create_map_win_loss_and_per_his_columns(data)\n",
    "tester = create_round_his_cols(tester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_excel('aggregated_dataset.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1216, 686)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mirage', 'Cache', 'Cobblestone'], dtype=object)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester.loc[(tester.player_team_name == 'NRG')&(tester.player_team_opponent=='SK'), 'map'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20      0.0\n",
       "19      0.0\n",
       "21      0.0\n",
       "69      0.0\n",
       "70      0.0\n",
       "93      0.0\n",
       "96      0.0\n",
       "100     0.0\n",
       "103     0.0\n",
       "112     0.0\n",
       "114     0.0\n",
       "123     0.0\n",
       "126     0.0\n",
       "127     0.0\n",
       "131     0.0\n",
       "133     0.0\n",
       "202     0.0\n",
       "204     0.0\n",
       "207     0.0\n",
       "206     0.0\n",
       "236     0.0\n",
       "260     0.0\n",
       "265     0.0\n",
       "307     0.0\n",
       "311     0.0\n",
       "318     0.0\n",
       "319     0.0\n",
       "341     0.0\n",
       "343     0.0\n",
       "345     0.0\n",
       "       ... \n",
       "826     0.0\n",
       "828     0.0\n",
       "830     0.0\n",
       "856     0.0\n",
       "859     0.0\n",
       "904     0.0\n",
       "906     0.0\n",
       "909     0.0\n",
       "912     0.0\n",
       "910     0.0\n",
       "913     0.0\n",
       "977     0.0\n",
       "980     0.0\n",
       "989     0.0\n",
       "992     0.0\n",
       "1020    0.0\n",
       "1026    0.0\n",
       "1042    0.0\n",
       "1047    0.0\n",
       "1054    0.0\n",
       "1061    0.0\n",
       "1078    0.0\n",
       "1113    0.0\n",
       "1115    0.0\n",
       "1132    0.0\n",
       "1141    0.0\n",
       "1144    0.0\n",
       "1184    0.0\n",
       "1185    0.0\n",
       "1186    0.0\n",
       "Name: rounds_loss_vs_SK_on_Overpass, Length: 99, dtype: float64"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester.loc[tester.player_team_name == 'NRG','rounds_loss_vs_SK_on_Overpass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tester.loc[(tester.player_team_name == 'NRG')&(tester.player_team_opponent=='CLG')].to_excel('map_team_breakdown_sanity_check.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_rounds_won_vs_team_his(data): # team rounds won vs another team    !6!\n",
    "    grouping = data.groupby(['match_id','map','team_A_name','team_B_name', 'team_A_score', 'team_B_score'])['round_num'].count()\n",
    "    grouping = pd.DataFrame(grouping)\n",
    "    grouping = grouping.add_suffix('_Count').reset_index()\n",
    "    grouping = grouping.groupby(['team_A_name', 'team_B_name']).sum()\n",
    "    grouping = pd.DataFrame(grouping)\n",
    "    grouping = grouping.add_suffix('_Count').reset_index()\n",
    "    forward = grouping.team_A_name+grouping.team_B_name\n",
    "    reverse = grouping.team_B_name+grouping.team_A_name\n",
    "    for idx, val in enumerate(forward):\n",
    "        for idx2, val2 in enumerate(reverse):\n",
    "            if val == val2 and idx < idx2:\n",
    "                grouping.loc[idx,'team_A_score_Count'] += grouping.loc[idx2,'team_B_score_Count']\n",
    "                grouping.loc[idx,'team_B_score_Count'] += grouping.loc[idx2,'team_A_score_Count']\n",
    "                grouping.loc[idx2,'team_B_score_Count'] = grouping.loc[idx,'team_A_score_Count']\n",
    "                grouping.loc[idx2,'team_A_score_Count'] = grouping.loc[idx,'team_B_score_Count']\n",
    "            elif val == val2 and idx > idx2:\n",
    "                grouping.loc[idx2,'team_B_score_Count'] = grouping.loc[idx,'team_A_score_Count']\n",
    "                grouping.loc[idx2,'team_A_score_Count'] = grouping.loc[idx,'team_B_score_Count']\n",
    "    \n",
    "    grouping = grouping.drop('round_num_Count_Count', axis = 1)\n",
    "    col1 = list(grouping.team_A_name.unique())\n",
    "    col2  = list(grouping.team_B_name.unique())\n",
    "    col = col1 + col2\n",
    "    col = list(set(col))\n",
    "    data = pd.merge(data,grouping, on=['team_A_name', 'team_B_name']) \n",
    "    for a in col:\n",
    "        data['rd_total_his_'+ a] = 0\n",
    "        data.loc[(data.player_team_name != a) & (data.team_A_name == a) , 'rd_total_his_'+ a]=data.team_B_score_Count\n",
    "        data.loc[(data.player_team_name != a) & (data.team_B_name == a) , 'rd_total_his_'+ a]=data.team_A_score_Count\n",
    "        bgrouping = data.groupby(['player_team_name'])['rd_total_his_'+ a].max()\n",
    "        bgrouping = pd.DataFrame(bgrouping)\n",
    "        bgrouping = bgrouping.reset_index()\n",
    "        data = data.drop('rd_total_his_'+ a, axis = 1)\n",
    "        data = pd.merge(data, bgrouping, on = 'player_team_name')\n",
    "       \n",
    "    return data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_total_team_rd_map_his(data):\n",
    "    grouping = data.groupby(['map','team_A_name', 'team_A_score'])['round_num'].count()\n",
    "    grouping = pd.DataFrame(grouping)\n",
    "    grouping = grouping.add_suffix('_Count').reset_index()\n",
    "    grouping = grouping.groupby(['map','team_A_name'])[ 'team_A_score'].sum()\n",
    "    grouping = pd.DataFrame(grouping)\n",
    "    grouping = grouping.add_suffix('_Count').reset_index()\n",
    "    fgrouping = data.groupby(['player_team_name','map','team_B_name', 'team_B_score'])['round_num'].count()\n",
    "    fgrouping = pd.DataFrame(fgrouping)\n",
    "    fgrouping = fgrouping.add_suffix('_Count').reset_index()\n",
    "    fgrouping = fgrouping.groupby(['map','team_B_name'])[ 'team_B_score'].sum()\n",
    "    fgrouping = pd.DataFrame(fgrouping)\n",
    "    fgrouping = fgrouping.add_suffix('_Count').reset_index()\n",
    "    fgrouping = fgrouping.rename(index=str, columns={\"team_B_name\": \"team_A_name\", 'team_B_score_Count': 'team_A_score_Count'})\n",
    "    merged = pd.concat([grouping, fgrouping], axis = 0)\n",
    "    merged.groupby(['map', 'team_A_name'])['team_A_score_Count'].sum()\n",
    "    merged = pd.DataFrame(merged)\n",
    "    merged = merged.reset_index(drop = True)\n",
    "    merged = merged.rename(index=str, columns={\"team_A_name\": \"player_team_name\", \"team_A_score_Count\": 'total_team_rd_map'})\n",
    "    merged = merged.groupby(['player_team_name', 'map']).sum()\n",
    "    merged = pd.DataFrame(merged)\n",
    "    merged = merged.reset_index()\n",
    "    for a in list(merged.map.unique()):\n",
    "        merged.loc[:,'total_team_rd_'+ a] = 0\n",
    "        merged.loc[(merged.loc[:, 'map'] == a), 'total_team_rd_'+ a] = merged.loc[:,'total_team_rd_map']\n",
    "        ok_map = merged.groupby(['player_team_name'])['total_team_rd_'+ a].max()\n",
    "        ok_map = pd.DataFrame(ok_map)\n",
    "        ok_map = ok_map.reset_index()\n",
    "        data = pd.merge(data, ok_map, on = 'player_team_name')\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#FUNCTIONS ABOVE HERE NEED TO BE WORKED ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data.to_pickle(\"data_converged_changed.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_list = ['first_kills', 'who_kill_who','awp_kills']\n",
    "data = create_fwa_dr_columns(data, col_list)\n",
    "data = create_fwadr_his(data,col_list)\n",
    "data = create_avdamage_his(data)\n",
    "data = create_map_win_loss_his(data)\n",
    "data = create_map_win_his_per(data)\n",
    "data = create_rounds_won_vs_team_his(data)\n",
    "data = create_total_team_rd_map_his(data)\n",
    "data = create_avdamage_map_his(data)\n",
    "data = create_faw_map_his(data, col_list)\n",
    "data = create_matches_count(data)\n",
    "data = create_opponent_team_col(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
