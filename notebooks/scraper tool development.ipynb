{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2, sys\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from IPython.core.display import HTML\n",
    "import requests\n",
    "import time\n",
    "import datetime\n",
    "import urlparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_teamID(team_name):\n",
    "    team_info = pd.read_csv('../../scrapped_data/team_info.csv', index_col=0)\n",
    "    teamID = team_info.loc[team_info.team_name == team_name, 'team_id'].tolist()[0]\n",
    "    return teamID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "    req = urllib2.Request(url,headers=hdr)\n",
    "    page = urllib2.urlopen(req)\n",
    "    soup = BeautifulSoup(page)\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_match_urls(params):\n",
    "    done=False\n",
    "    params['offset'] = 0\n",
    "    urls = []\n",
    "    while not done:\n",
    "        match_page = \"https://www.hltv.org/results?offset={offset}&content=demo&team={teamID}&startDate={startDate}&endDate={endDate}\".format(**params)\n",
    "        soup = get_soup(match_page)\n",
    "        matches = soup.find_all(\"div\", class_='results-all')\n",
    "        \n",
    "        if len(matches) == 0:\n",
    "            break\n",
    "        \n",
    "        results = matches[0].find_all(\"a\", class_=\"a-reset\")\n",
    "        urls  += ['https://www.hltv.org' + result['href'] for result in results]\n",
    "        if len(urls) % 100 != 0:\n",
    "            done = True\n",
    "        else:\n",
    "            params['offset'] += 100\n",
    "    del params['offset']\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_match(site):\n",
    "    soup = get_soup(site)\n",
    "\n",
    "    demo_url = 'https://www.hltv.org' + soup.find_all(\"a\", class_=\"flexbox left-right-padding\")[0]['href']\n",
    "    best_of_1 = False\n",
    "    try:\n",
    "        vetos = soup.find_all(\"div\", class_=\"standard-box veto-box\")[1].find_all(\"div\")[0].find_all(\"div\")\n",
    "        vetos = [veto.text for veto in vetos]\n",
    "    except:\n",
    "        vetos = None\n",
    "        best_of_1 = True\n",
    "        \n",
    "    team_name = soup.find_all(\"div\", class_=\"standard-box teamsBox\")[0].find_all(\"div\", class_ = \"teamName\")\n",
    "    team_info = soup.find_all(\"div\", class_=\"flexbox fix-half-width-margin maps\")[0].find_all(\"div\", class_ = \"results\")\n",
    "\n",
    "    for name in team_name[0]:\n",
    "        team_a_name = name\n",
    "    for name in team_name[1]:\n",
    "        team_b_name = name\n",
    "    best_of = soup.find_all(\"div\", class_ = \"padding preformatted-text\")\n",
    "    for best in best_of:\n",
    "        best_of = best.text\n",
    "    if \"Best of 3\" in best_of:\n",
    "        best_of = \"Best of 3\"\n",
    "        map_name_one = soup.find_all(\"div\", class_ = \"mapname\")[0]\n",
    "        for name in map_name_one:\n",
    "            map_name_one = name\n",
    "        map_name_two = soup.find_all(\"div\", class_ = \"mapname\")[1]\n",
    "        for name in map_name_two:\n",
    "            map_name_two = name\n",
    "        map_name_three = soup.find_all(\"div\", class_ = \"mapname\")[2]\n",
    "        for name in map_name_three:\n",
    "            map_name_three = name\n",
    "\n",
    "\n",
    "        team_a_score_map_one = team_info[0].find_all(\"span\")[0].text\n",
    "        team_b_score_map_one = team_info[0].find_all(\"span\")[2].text\n",
    "        team_a_score_map_two = team_info[1].find_all(\"span\")[0].text\n",
    "        team_b_score_map_two = team_info[1].find_all(\"span\")[2].text\n",
    "        try:\n",
    "            team_a_score_map_three = team_info[2].find_all(\"span\")[0].text\n",
    "            team_b_score_map_three = team_info[2].find_all(\"span\")[2].text\n",
    "\n",
    "        except: \n",
    "            team_b_score_map_three = 'NA'\n",
    "            team_a_score_map_three = 'NA'\n",
    "        \n",
    "       \n",
    "    elif \"Best of 1\" in best_of:\n",
    "        best_of = \"Best of 1\"\n",
    "        map_name_one = soup.find_all(\"div\", class_ = \"mapname\")[0]\n",
    "        for name in map_name_one:\n",
    "            map_name_one = name\n",
    "        team_a_score_map_one = team_info[0].find_all(\"span\")[0].text\n",
    "        team_b_score_map_one = team_info[0].find_all(\"span\")[2].text\n",
    "        map_name_two = team_a_score_map_two = team_b_score_map_two = map_name_three = team_a_score_map_three = team_b_score_map_three = 'NA'\n",
    "       \n",
    "    else:\n",
    "        print(\"new type of match format\")\n",
    "        \n",
    "    stats_url = 'https://www.hltv.org' + [a_element['href'] for a_element in soup.find_all(\"a\") if a_element.text == \"Detailed stats\"][0]\n",
    "\n",
    "\n",
    "    \n",
    "    hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "    r = requests.get(site, headers=hdr)\n",
    "    tables = pd.read_html(r.text, header=0)\n",
    "    team_a, team_b = tables[0], tables[1]\n",
    "\n",
    "    match_data = {\n",
    "        'team_a_b' : (team_a_name, team_b_name),\n",
    "        'map_one': (map_name_one, team_a_score_map_one, team_b_score_map_one),\n",
    "        'map_two': (map_name_two, team_a_score_map_two, team_b_score_map_two),\n",
    "        'map_three': (map_name_three, team_a_score_map_three, team_b_score_map_three),\n",
    "        'url': site,\n",
    "        'vetos': vetos,\n",
    "        'stats_url': stats_url,\n",
    "        'teams': [team_a, team_b]\n",
    "    }\n",
    "    \n",
    "    ## this stuff should all be moved to another function which aggregates all sites\n",
    "    map_stats_url = 'https://www.hltv.org/stats/matches/mapstatsid/'+ stats_url.split('/')[5] + '/'+ stats_url.split('/')[6]\n",
    "    preformance_url ='https://www.hltv.org/stats/matches/performance/mapstatsid/'+ stats_url.split('/')[5] + '/'+ stats_url.split('/')[6]\n",
    "    \n",
    "    stats_data = parse_stats_page(map_stats_url)\n",
    "    preformance_data = parse_stats_performance_page(preformance_url)\n",
    "    \n",
    "    match_data.update(stats_data)\n",
    "    match_data.update(preformance_data)\n",
    "    \n",
    "    return match_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scrape_match_data(team_name, startDate, endDate):\n",
    "    teamID = get_teamID(team_name)\n",
    "    params = {\n",
    "        'teamID':teamID,\n",
    "        'startDate':startDate,\n",
    "        'endDate':endDate\n",
    "    }\n",
    "    urls = get_match_urls(params)\n",
    "    matches = []\n",
    "    for idx, url in enumerate(urls):\n",
    "        matches.append(parse_match(url))\n",
    "        time.sleep(5)\n",
    "        print 'match {0} done'.format(idx)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_stats_performance_page(url): \n",
    "    #site page example \"https://www.hltv.org/stats/matches/performance/mapstatsid/52325/immortals-vs-cloud9\"\n",
    "    # THIS THE STATS/PERFORMANCE PAGE\n",
    "    hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "    r = requests.get(url, headers=hdr)\n",
    "    tables = pd.read_html(r.text, header=0)\n",
    "    total_team_kda = tables[0] \n",
    "    who_kill_who = tables[1] \n",
    "    first_kills = tables[2]  \n",
    "    awp_kills = tables[3]   \n",
    "    \n",
    "    return {\n",
    "        'total_team_kda': total_team_kda, # total kills deaths and assists of team\n",
    "        'who_kill_who' : who_kill_who, # who killed who\n",
    "        'first_kills' : first_kills, #first kill of the round\n",
    "        'awp_kills' : awp_kills #awp kills\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_stats_page(url): \n",
    "    #site page example  \"https://www.hltv.org/stats/matches/mapstatsid/52325/immortals-vs-cloud9\"\n",
    "    # THIS IS THE STATS PAGE\n",
    "    \n",
    "    soup = get_soup(url)\n",
    "  \n",
    "    match_time = soup.find_all(\"div\", {\"class\":\"small-text\"})\n",
    "    for item in match_time:\n",
    "        match_time = item.text\n",
    "    match_time = datetime.datetime.strptime(match_time, '%Y-%m-%d  %H:%MMap') #match date and time\n",
    "    hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "    r = requests.get(url, headers=hdr)\n",
    "    tables = pd.read_html(r.text, header=0)\n",
    "    team_a_stats, team_b_stats = tables[0], tables[1]\n",
    "\n",
    "    round_history_team = soup.find_all(\"div\", class_ = \"round-history-team-row\") # winner of rounds and how rounds were won\n",
    "    round_history_team_a = round_history_team[0].find_all(\"img\")\n",
    "    round_history_team_b = round_history_team[1].find_all(\"img\")\n",
    "    team_a_scores = []\n",
    "    for scoreing in round_history_team_a:\n",
    "         team_a_scores.append([ scoreing.get('title')])                    #rounds that team a won\n",
    "    team_b_scores = []                                                         \n",
    "    for scoreing in round_history_team_b:                              \n",
    "         team_b_scores.append([ scoreing.get('title')])                    #rounds that team b won\n",
    "    team_a_ending = []                                                          \n",
    "    for ending in round_history_team_a:\n",
    "        url = urlparse.urlparse(ending.get('src'))\n",
    "        base = os.path.basename(url.path)                                  #how team a won the round\n",
    "        team_a_ending.append([os.path.splitext(base)[0]])   \n",
    "    team_b_ending = []\n",
    "    for ending in round_history_team_b:\n",
    "        url = urlparse.urlparse(ending.get('src'))\n",
    "        base = os.path.basename(url.path)\n",
    "        team_b_ending.append([os.path.splitext(base)[0]])                  #how team b won the round\n",
    "    return {\n",
    "        'match_time' : match_time, #match date and time\n",
    "        'team_scores': [team_a_scores, team_b_scores], #rounds that team a won\n",
    "        'team_endings': [team_a_ending, team_b_ending] #how the team won the round\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mckak\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 174 of the file C:\\Users\\mckak\\Anaconda2\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match 0 done\n"
     ]
    }
   ],
   "source": [
    "#testing function\n",
    "\n",
    "team_name = 'TyLoo'\n",
    "startDate ='2017-08-01'\n",
    "endDate ='2017-10-01'\n",
    "\n",
    "matches = scrape_match_data(team_name, startDate, endDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'awp_kills':   Unnamed: 0  MKN Baltec HugoXD Plopski xole\n",
       "  0     robiin  0:0    0:0    0:0     0:0  1:0\n",
       "  1     Konshi  0:0    0:0    0:0     0:0  0:0\n",
       "  2       Sayf  0:0    0:0    0:1     0:0  0:0\n",
       "  3    b0bbzki  0:0    0:0    0:0     0:0  0:0\n",
       "  4     BENDJI  2:0    0:0    0:0     3:0  0:0,\n",
       "  'first_kills':   Unnamed: 0  MKN Baltec HugoXD Plopski xole\n",
       "  0     robiin  0:0    1:0    1:0     1:0  3:0\n",
       "  1     Konshi  0:0    1:0    0:1     1:0  0:0\n",
       "  2       Sayf  2:0    3:1    1:0     0:1  0:0\n",
       "  3    b0bbzki  0:0    0:0    0:0     0:0  2:1\n",
       "  4     BENDJI  0:0    0:0    1:1     0:0  0:1,\n",
       "  'map_one': (u'Overpass', u'16', u'12'),\n",
       "  'map_three': (u'Cache', u'8', u'16'),\n",
       "  'map_two': (u'Inferno', u'9', u'16'),\n",
       "  'match_time': datetime.datetime(2017, 6, 11, 19, 25),\n",
       "  'stats_url': 'https://www.hltv.org/stats/matches/47764/tyloo-vs-flash',\n",
       "  'team_a_b': (u'TyLoo', u'Flash'),\n",
       "  'team_endings': [[['7933'],\n",
       "    ['ct_win'],\n",
       "    ['bomb_defused'],\n",
       "    ['emptyHistory'],\n",
       "    ['emptyHistory'],\n",
       "    ['ct_win'],\n",
       "    ['emptyHistory'],\n",
       "    ['emptyHistory'],\n",
       "    ['emptyHistory'],\n",
       "    ['emptyHistory'],\n",
       "    ['emptyHistory'],\n",
       "    ['emptyHistory'],\n",
       "    ['ct_win'],\n",
       "    ['emptyHistory'],\n",
       "    ['ct_win'],\n",
       "    ['emptyHistory'],\n",
       "    ['emptyHistory'],\n",
       "    ['emptyHistory'],\n",
       "    ['emptyHistory'],\n",
       "    ['bomb_exploded'],\n",
       "    ['bomb_exploded'],\n",
       "    ['emptyHistory'],\n",
       "    ['emptyHistory'],\n",
       "    ['emptyHistory'],\n",
       "    ['emptyHistory'],\n",
       "    ['emptyHistory'],\n",
       "    ['emptyHistory'],\n",
       "    ['emptyHistory'],\n",
       "    ['emptyHistory'],\n",
       "    ['emptyHistory'],\n",
       "    ['emptyHistory']],\n",
       "   [['7823'],\n",
       "    ['emptyHistory'],\n",
       "    ['emptyHistory'],\n",
       "    ['t_win'],\n",
       "    ['bomb_exploded'],\n",
       "    ['emptyHistory'],\n",
       "    ['t_win'],\n",
       "    ['t_win'],\n",
       "    ['bomb_exploded'],\n",
       "    ['t_win'],\n",
       "    ['t_win'],\n",
       "    ['t_win'],\n",
       "    ['emptyHistory'],\n",
       "    ['t_win'],\n",
       "    ['emptyHistory'],\n",
       "    ['t_win'],\n",
       "    ['ct_win'],\n",
       "    ['ct_win'],\n",
       "    ['ct_win'],\n",
       "    ['emptyHistory'],\n",
       "    ['emptyHistory'],\n",
       "    ['bomb_defused'],\n",
       "    ['ct_win'],\n",
       "    ['ct_win'],\n",
       "    ['emptyHistory'],\n",
       "    ['emptyHistory'],\n",
       "    ['emptyHistory'],\n",
       "    ['emptyHistory'],\n",
       "    ['emptyHistory'],\n",
       "    ['emptyHistory'],\n",
       "    ['emptyHistory']]],\n",
       "  'team_scores': [[['Atleterna'],\n",
       "    ['1-0'],\n",
       "    ['2-0'],\n",
       "    [''],\n",
       "    [''],\n",
       "    ['3-2'],\n",
       "    [''],\n",
       "    [''],\n",
       "    [''],\n",
       "    [''],\n",
       "    [''],\n",
       "    [''],\n",
       "    ['4-8'],\n",
       "    [''],\n",
       "    ['5-9'],\n",
       "    [''],\n",
       "    [''],\n",
       "    [''],\n",
       "    [''],\n",
       "    ['6-13'],\n",
       "    ['7-13'],\n",
       "    [''],\n",
       "    [''],\n",
       "    [''],\n",
       "    [''],\n",
       "    [''],\n",
       "    [''],\n",
       "    [''],\n",
       "    [''],\n",
       "    [''],\n",
       "    ['']],\n",
       "   [['fightclub'],\n",
       "    [''],\n",
       "    [''],\n",
       "    ['2-1'],\n",
       "    ['2-2'],\n",
       "    [''],\n",
       "    ['3-3'],\n",
       "    ['3-4'],\n",
       "    ['3-5'],\n",
       "    ['3-6'],\n",
       "    ['3-7'],\n",
       "    ['3-8'],\n",
       "    [''],\n",
       "    ['4-9'],\n",
       "    [''],\n",
       "    ['5-10'],\n",
       "    ['5-11'],\n",
       "    ['5-12'],\n",
       "    ['5-13'],\n",
       "    [''],\n",
       "    [''],\n",
       "    ['7-14'],\n",
       "    ['7-15'],\n",
       "    ['7-16'],\n",
       "    [''],\n",
       "    [''],\n",
       "    [''],\n",
       "    [''],\n",
       "    [''],\n",
       "    [''],\n",
       "    ['']]],\n",
       "  'teams': [                            TyLoo    K-D  +/-   ADR   KAST  Rating2.0\n",
       "   0  HaoWen 'somebody' Xu  somebody  70-52   18  88.8  74.0%       1.28\n",
       "   1             Zhen 'HZ' Huang  HZ  53-52    1  78.0  76.6%       1.09\n",
       "   2                 Ke 'Mo' Liu  Mo  55-53    2  75.8  67.5%       1.08\n",
       "   3        ZhenDong 'Not7' Mo  Not7  42-57  -15  60.4  67.5%       0.83\n",
       "   4                 Hui 'DD' Wu  DD  38-59  -21  66.3  57.1%       0.75,\n",
       "                                     Flash    K-D  +/-   ADR   KAST  Rating2.0\n",
       "   0  YuanZhang 'AttackeR' Sheng  AttackeR  69-46   23  92.3  76.6%       1.41\n",
       "   1            YuLun 'fancy1' Cai  fancy1  60-54    6  84.5  76.6%       1.23\n",
       "   2           KunHua 'LOVEYY' Bai  LOVEYY  51-49    2  74.8  68.8%       1.08\n",
       "   3              QiFang 'Karsa' Su  Karsa  52-54   -2  79.5  76.6%       1.05\n",
       "   4           WeiJia 'INNOPY' Guo  INNOPY  41-55  -14  58.8  79.2%       0.90],\n",
       "  'total_team_kda':   Unnamed: 0  Unnamed: 1    Â  Unnamed: 3\n",
       "  0      Kills          56  Â Â          91\n",
       "  1     Deaths          92  Â Â          56\n",
       "  2    Assists          11  Â Â          22,\n",
       "  'url': 'https://www.hltv.org/matches/2314604/tyloo-vs-flash-wesg-2017-china-finals',\n",
       "  'vetos': [u'1. TyLoo removed Nuke',\n",
       "   u'2. Flash removed Mirage',\n",
       "   u'3. TyLoo picked Overpass',\n",
       "   u'4. Flash picked Inferno',\n",
       "   u'5. TyLoo removed Train',\n",
       "   u'6. Flash removed Cobblestone',\n",
       "   u'7. Cache was left over'],\n",
       "  'who_kill_who':   Unnamed: 0  MKN Baltec HugoXD Plopski xole\n",
       "  0     robiin  5:2    2:4    5:3     5:1  7:2\n",
       "  1     Konshi  1:1    6:2    6:1     2:2  3:2\n",
       "  2       Sayf  8:4    9:1    3:3     2:1  2:2\n",
       "  3    b0bbzki  1:3    1:0    2:2     3:5  3:4\n",
       "  4     BENDJI  4:2    1:2    3:1     5:4  2:2}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
